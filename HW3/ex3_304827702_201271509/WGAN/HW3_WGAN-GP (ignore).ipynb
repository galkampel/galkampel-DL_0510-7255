{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HW3_WGAN-GP.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"21ccf970b84d4f5b95be8c3a88c0ab30":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a5674d2b1e154add868ffe2170ae46d8","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_653df475dcf74ac0b3a46ac654015ce9","IPY_MODEL_d57b33f5c67f4ad999116b8c881095b9"]}},"a5674d2b1e154add868ffe2170ae46d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"653df475dcf74ac0b3a46ac654015ce9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0c02907868de4532b2cdeeef696c8b77","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8a161838dc504d69945d0cfa87d1e421"}},"d57b33f5c67f4ad999116b8c881095b9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0bd4b6dc6adb4ca3a78b5a6960411cb2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 26427392/? [00:19&lt;00:00, 3616312.27it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9493dc32e6874ca0bee7c7e9bb0432d6"}},"0c02907868de4532b2cdeeef696c8b77":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8a161838dc504d69945d0cfa87d1e421":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0bd4b6dc6adb4ca3a78b5a6960411cb2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9493dc32e6874ca0bee7c7e9bb0432d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"287c1a9f31034a749c653d6a8223910f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e12dafbb064a49fea959fc58ff0def2b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6353374db19845e7b04da5bf0dc8498c","IPY_MODEL_c7f81d76aaaf48509760c190eb1c00c1"]}},"e12dafbb064a49fea959fc58ff0def2b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6353374db19845e7b04da5bf0dc8498c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5960cc26647e4559a7a1d136e7987ea4","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_93254fb66f65415286508aa4965caa78"}},"c7f81d76aaaf48509760c190eb1c00c1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a76744055ed0456797d4c52812bbc3a0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 32768/? [00:04&lt;00:00, 7528.34it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b4046fb8a51b4cd0b0699ce96b79fb28"}},"5960cc26647e4559a7a1d136e7987ea4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"93254fb66f65415286508aa4965caa78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a76744055ed0456797d4c52812bbc3a0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b4046fb8a51b4cd0b0699ce96b79fb28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c3fdc90354fe42748794847d701120ce":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_00d777f369fb4507ad44f80763e04cc4","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8f66b9e2e780454e8151e667afc0cb3b","IPY_MODEL_1cd94e8abb43450bbc36ee15997d406e"]}},"00d777f369fb4507ad44f80763e04cc4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8f66b9e2e780454e8151e667afc0cb3b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8c5497f98b6146cbaafb65f736cbedf4","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_074bfab209eb4b8d835b461e28e3aa92"}},"1cd94e8abb43450bbc36ee15997d406e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1ea14201994b401eb29f2c0dd6f20d15","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 4423680/? [00:03&lt;00:00, 1259571.65it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_114870ff0df14748a07e9b4a3e582fe1"}},"8c5497f98b6146cbaafb65f736cbedf4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"074bfab209eb4b8d835b461e28e3aa92":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1ea14201994b401eb29f2c0dd6f20d15":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"114870ff0df14748a07e9b4a3e582fe1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"006aa5e8a31648638e09d5615f364012":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_097b6b09a268426ea482b3ba1ddeb4eb","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_878b575267344aeaae22a5a7e13088a7","IPY_MODEL_afd67db5b61e48508dbcfd6b42458332"]}},"097b6b09a268426ea482b3ba1ddeb4eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"878b575267344aeaae22a5a7e13088a7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_cded31582c824d1e8346c7a54bc6c4b5","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3dbdb6567caa496ca9f56943d3a0c572"}},"afd67db5b61e48508dbcfd6b42458332":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f2021157cfe84271b0735ee80ea627a1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 8192/? [00:00&lt;00:00, 10836.24it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4bc4184ca3ba4c159dae5f041dd813d8"}},"cded31582c824d1e8346c7a54bc6c4b5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3dbdb6567caa496ca9f56943d3a0c572":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f2021157cfe84271b0735ee80ea627a1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4bc4184ca3ba4c159dae5f041dd813d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"RCW4Re086f1K","colab_type":"text"},"source":["# **HW3- WGAN-GP**"]},{"cell_type":"code","metadata":{"id":"yFBl9avc-q8T","colab_type":"code","outputId":"148b47af-9914-4a9e-cfd4-d1b1140c85ac","executionInfo":{"status":"ok","timestamp":1591507379702,"user_tz":-180,"elapsed":1938,"user":{"displayName":"Gal Kampel","photoUrl":"","userId":"12072246612200432478"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib\n","import matplotlib.pyplot as plt\n","from tqdm import trange\n","from datetime import datetime\n","from collections import OrderedDict, Counter\n","from itertools import product\n","from prettytable import PrettyTable\n","import os\n","import random"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"c7365J3P-rAv","colab_type":"code","colab":{}},"source":["import torch\n","import torchvision\n","from torch import nn, optim\n","from torch.optim import lr_scheduler\n","from torch.utils.data import DataLoader\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms\n","import torch.autograd as autograd\n","import torchvision.utils as vutils\n","from torch.utils.tensorboard import SummaryWriter\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-fKxUwl3-rCH","colab_type":"code","outputId":"0cf8d426-5eb3-4c3f-f7a9-22e1be0fa7fe","executionInfo":{"status":"ok","timestamp":1591507383276,"user_tz":-180,"elapsed":5491,"user":{"displayName":"Gal Kampel","photoUrl":"","userId":"12072246612200432478"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["SEED = 0\n","torch.manual_seed(SEED)\n","random.seed(SEED)\n","torch.cuda.is_available()"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"Ctux_6Kd8lUF","colab_type":"code","outputId":"1caf84d6-783a-4cb6-bc6c-b4b1fd2ba8d3","executionInfo":{"status":"ok","timestamp":1591507412481,"user_tz":-180,"elapsed":34684,"user":{"displayName":"Gal Kampel","photoUrl":"","userId":"12072246612200432478"}},"colab":{"base_uri":"https://localhost:8080/","height":143}},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","ROOT_PATH = '/content/drive/My Drive/DL-Raja/HW3/ex3_304827702_201271509/WGAN'\n","os.chdir(ROOT_PATH)\n","os.getcwd()"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["'/content/drive/My Drive/DL-Raja/HW3/ex3_304827702_201271509/WGAN'"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"T1i2vXFGWlhN","colab_type":"text"},"source":["# **Load Fashion MNIST dataset**"]},{"cell_type":"code","metadata":{"id":"85jFkjWYmY_b","colab_type":"code","colab":{}},"source":["# ImageSize = 32 #warp input image s.t. height=width=32\n","# def load_FMNIST_dataset(transform, train=True):\n","#     return torchvision.datasets.FashionMNIST(\n","#                 root = '~/.pytorch/F_MNIST_data/',\n","#                 train = train,\n","#                 download = True,\n","#                 transform = transform\n","#             )\n","# # each channel is normalized to be in the range [-1,1] (only one channel (grayscale))\n","# TRANSFORM = transforms.Compose([\n","#                                 transforms.Resize(32),\n","#                                 transforms.ToTensor()] \n","#                                 ])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kvU1_Q9aNcEZ","colab_type":"code","colab":{}},"source":["# ######## OLD ############\n","# # ImageSize = 32 #warp input image s.t. height=width=32\n","def load_FMNIST_dataset(transform, train=True):\n","    return torchvision.datasets.FashionMNIST(\n","                root = '~/.pytorch/F_MNIST_data/',\n","                train = train,\n","                download = True,\n","                transform = transform\n","            )\n","# each channel is normalized to be in the range [-1,1] (only one channel (grayscale))\n","TRANSFORM = transforms.Compose([\n","                                transforms.ToTensor(),\n","                                transforms.Normalize((0.5,), (0.5,))] \n","                                )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vOjraNF0owQx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":359,"referenced_widgets":["21ccf970b84d4f5b95be8c3a88c0ab30","a5674d2b1e154add868ffe2170ae46d8","653df475dcf74ac0b3a46ac654015ce9","d57b33f5c67f4ad999116b8c881095b9","0c02907868de4532b2cdeeef696c8b77","8a161838dc504d69945d0cfa87d1e421","0bd4b6dc6adb4ca3a78b5a6960411cb2","9493dc32e6874ca0bee7c7e9bb0432d6","287c1a9f31034a749c653d6a8223910f","e12dafbb064a49fea959fc58ff0def2b","6353374db19845e7b04da5bf0dc8498c","c7f81d76aaaf48509760c190eb1c00c1","5960cc26647e4559a7a1d136e7987ea4","93254fb66f65415286508aa4965caa78","a76744055ed0456797d4c52812bbc3a0","b4046fb8a51b4cd0b0699ce96b79fb28","c3fdc90354fe42748794847d701120ce","00d777f369fb4507ad44f80763e04cc4","8f66b9e2e780454e8151e667afc0cb3b","1cd94e8abb43450bbc36ee15997d406e","8c5497f98b6146cbaafb65f736cbedf4","074bfab209eb4b8d835b461e28e3aa92","1ea14201994b401eb29f2c0dd6f20d15","114870ff0df14748a07e9b4a3e582fe1","006aa5e8a31648638e09d5615f364012","097b6b09a268426ea482b3ba1ddeb4eb","878b575267344aeaae22a5a7e13088a7","afd67db5b61e48508dbcfd6b42458332","cded31582c824d1e8346c7a54bc6c4b5","3dbdb6567caa496ca9f56943d3a0c572","f2021157cfe84271b0735ee80ea627a1","4bc4184ca3ba4c159dae5f041dd813d8"]},"outputId":"2e2904be-817c-4679-8006-b90a4e0dddb6","executionInfo":{"status":"ok","timestamp":1591507435501,"user_tz":-180,"elapsed":10316,"user":{"displayName":"Gal Kampel","photoUrl":"","userId":"12072246612200432478"}}},"source":["BATCH_SIZE = 32\n","training_set = load_FMNIST_dataset(TRANSFORM)\n","train_loader = torch.utils.data.DataLoader(training_set, batch_size = BATCH_SIZE, shuffle=True)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"21ccf970b84d4f5b95be8c3a88c0ab30","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-images-idx3-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"287c1a9f31034a749c653d6a8223910f","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c3fdc90354fe42748794847d701120ce","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"006aa5e8a31648638e09d5615f364012","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw\n","Processing...\n","Done!\n"],"name":"stdout"},{"output_type":"stream","text":["/pytorch/torch/csrc/utils/tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"HFKLpyUtNRYL","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"flS_du31NRT8","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fBkRwp2y6m4i","colab_type":"text"},"source":["### Create random noise and real images"]},{"cell_type":"code","metadata":{"id":"VkkGpXPa6pKW","colab_type":"code","colab":{}},"source":["def create_noise(n_samples=4, z_dim=100, device=\"cpu\" , fixed=False, seed=1):\n","    if fixed:\n","        torch.manual_seed(seed)\n","    # noise = torch.randn(n_samples, z_dim, device=device).float()\n","    noise = 2 * torch.rand(n_samples, z_dim, device=device).float() - 1\n","    return noise\n","\n","def get_real_imgs(data_loader, class_labels):\n","    test_imgs, test_labels = iter(data_loader).next()\n","    real_imgs = []\n","    for class_label in class_labels:\n","        imgs = test_imgs[test_labels == class_label][0]\n","        real_imgs.append(imgs.cpu().numpy())\n","    \n","    return real_imgs"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DmjnRxOgJB4t","colab_type":"text"},"source":["#**WGAN-GP class**"]},{"cell_type":"code","metadata":{"id":"KTB6Rv1qFNZ5","colab_type":"code","colab":{}},"source":["def create_gen_block(c_in, c_out, k, s, padding):\n","    return nn.Sequential(\n","        nn.ConvTranspose2d(c_in, c_out, k, s, padding, bias=False),\n","        nn.BatchNorm2d(c_out),\n","        nn.ReLU(True)\n","        )\n","    \n","class GeneratorWGANGP(nn.Module):\n","    def __init__(self, z_dim=100, c_out=128, k=4, s=2, padding=1, c_in=1):\n","        super(GeneratorWGANGP, self).__init__()\n","        self.c_out = c_out\n","        # input is (c_in) x z_dim -> (c_out * 4) x 7 x 7\n","        self.fc1 = nn.Sequential(\n","             nn.Linear(z_dim, c_out * 4 * (7 * 7)),\n","             nn.ReLU(True),\n","        )\n","        # (c_out * 4) x 7 x 7 -> (c_out * 2) x 14 x 14\n","        self.B1 = create_gen_block(c_out * 4 ,c_out * 2, k, s, padding)\n","        # (c_out * 2) x 14 x 14 -> c_out x 28 x 28\n","        self.B2 = create_gen_block(c_out * 2, c_out, k, s, padding)\n","        # c_out x 28 x 28 -> 1 x 28 x 28\n","        self.conv = nn.Conv2d(c_out, c_in, 1, stride=1, padding=0)\n","\n","    def forward(self, x):\n","        fc1_out = self.fc1(x)\n","        fc1_out = fc1_out.view(-1, 4 * self.c_out, 7, 7)\n","        b1_out = self.B1(fc1_out)\n","        b2_out = self.B2(b1_out)\n","        output = torch.sigmoid(self.conv(b2_out))\n","        return output\n","\n","\n","def create_critic_block(c_in, c_out, k, s, padding, p):\n","    return nn.Sequential(\n","        nn.Conv2d(c_in, c_out, k, s, padding, bias=False),\n","        nn.LeakyReLU(p, inplace=True),\n","    )\n","\n","\n","class Critic(nn.Module):\n","    def __init__(self, c_in=1, c_out=64, k=5, s=2, padding=2, p=0.2, h_in=28):\n","        super(Critic, self).__init__()\n","        self.c_in = c_in\n","        self.c_out = c_out\n","        self.h_in = h_in\n","        # input is (c_in) x 28 x 28 -> (c_out) x 14 x 14\n","        self.B1 = create_critic_block(c_in, c_out, k, s, padding, p)\n","        # (c_out) x 14 x 14 -> (c_out * 2) x 7 x 7\n","        self.B2 = create_critic_block(c_out, c_out * 2, k, s, padding, p)\n","        # (c_out * 2) x 7 x 7 -> (c_out * 4) x 4 x 4\n","        self.B3 = create_critic_block(c_out* 2, c_out * 4, k, s, padding, p)\n","        #  (4 * c_out) x 4 x 4 -> (4 * 4 * 4 c_out) x 1 x 1\n","        self.fc = nn.Linear(4 * (4 * 4) * c_out, c_in)\n","\n","    def forward(self, x):\n","        x = x.view(-1, self.c_in, self.h_in, self.h_in)\n","        b1_out = self.B1(x)\n","        b2_out = self.B2(b1_out)\n","        b3_out = self.B3(b2_out)\n","        b3_out = b3_out.view(-1, 4 * (4 * 4) *self.c_out)\n","        # output = self.fc(b3_out)\n","        output = torch.sigmoid(self.fc(b3_out))\n","        # return output.view(-1)\n","        return output\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A-g31FnYBiqt","colab_type":"text"},"source":["## Hyperparameters generator"]},{"cell_type":"code","metadata":{"id":"7Cdpk2pbEKJX","colab_type":"code","colab":{}},"source":["class HyperparamsConfig:\n","    def __init__(self, hyperparams_dict): \n","        self.hyperparams_dict = hyperparams_dict\n","        self.hyperparams_names = list(hyperparams_dict.keys())\n","\n","    def create_configs(self):\n","        h_params_names = self.hyperparams_names\n","        for h_params_vals in product(*[h_params  for h_params in self.hyperparams_dict.values()]):\n","            yield {h_params_name: h_params_vals[i] for i, h_params_name in enumerate(h_params_names)}\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m2TvlcVrBrcV","colab_type":"text"},"source":["## Model configuration per run \n","* Create  a new WGAN model acclording to specific configuration (if starting epoch=0)\n","* Enabing load saved model with its optimizer, scheduler and starting epoch"]},{"cell_type":"code","metadata":{"id":"u-8nPV76yRvL","colab_type":"code","colab":{}},"source":["class ModelRun:\n","    def __init__(self, model, model_type, config, epochs, device, trained_model_path=''):\n","        self.config = config\n","        self.epochs = epochs\n","        self.model_name = ''\n","        self.device = device\n","        self.start_epoch = 0\n","        self.model = model\n","        self.optimizer = self.set_optimizer(model_type)\n","        self.scheduler = lr_scheduler.CosineAnnealingLR(self.optimizer,epochs)\n","        self.loss = []\n","        if trained_model_path != '' and os.path.exists(trained_model_path):\n","            self.load_model(trained_model_path)\n","\n","            \n","    \n","    def set_optim_params(self, param_groups, params_dict):\n","        weight_decay = self.config.get('weight_decay', 0.0)\n","        if weight_decay > 0:\n","            params_dict['weight_decay'] = weight_decay\n","        for param_name, param_val in  params_dict.items():\n","            param_groups[param_name] = param_val\n","\n","\n","    def set_optimizer(self, model_type):\n","        model = self.model\n","        model.to(self.device)\n","        config = self.config\n","        optimizer_dict = config['optimizer_dict']\n","        optim_name = optimizer_dict['optim_name']\n","        self.set_model_name(optim_name, model_type)\n","        lr = self.config['lr']\n","        optimizer = optimizer_dict['optim_func'](model.parameters(), lr=lr)\n","        optimizer_params_dict = optimizer_dict['optim_params']\n","        self.set_optim_params(optimizer.param_groups[0], optimizer_params_dict)\n","        return optimizer\n","\n","\n","    def set_model_name(self, optim_name, model_type):\n","        config = self.config\n","        lr = config.get('lr')\n","        weight_decay = config.get('weight_decay', 0.0) \n","        self.model_name = f\"WGAN-GP_{model_type}_optimizer={optim_name}_\" \\\n","                          f\"lr={lr}_weight_decay={weight_decay}\"\n","\n","\n","    def get_model(self):\n","        return self.model\n","         \n","    def get_device(self):\n","        return self.device\n","\n","    def get_max_grad_norm(self):\n","        return self.max_grad_norm\n","\n","    def get_optimizer(self):\n","        return self.optimizer\n","    \n","    def get_scheduler(self):\n","        return self.scheduler\n","\n","    def get_model_name(self):\n","        return self.model_name\n","    \n","    def get_loss(self):\n","        return self.loss\n","\n","    def get_epochs(self):\n","        return self.epochs\n","\n","    def get_start_epoch(self):\n","        return self.start_epoch\n","         \n","    def load_model(self, path_model):\n","        checkpoint = torch.load(path_model)\n","        self.model.load_state_dict(checkpoint['model_state_dict'])\n","        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","        self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n","        self.loss = checkpoint['loss']\n","        self.iters = checkpoint['iters']\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l48ZrK6fCfiE","colab_type":"text"},"source":["## Run configuration\n","* fit and evaluate on validation\n","* scalar plot (tensorboard) and train-validation plot\n","* enable saving the model during training"]},{"cell_type":"code","metadata":{"id":"z_y-B4Jiadcv","colab_type":"code","colab":{}},"source":["class RunConfig:\n","    def __init__(self, model_G_config, model_C_config, device, critic_iters=1, save_every=1,\n","                 save_model=True, folder_checkpoint=''):\n","        \n","        # self.criterion = nn.BCELoss()\n","        self.save_model = save_model\n","        self.save_every = save_every\n","        self.model_G_config = model_G_config\n","        self.model_C_config = model_C_config\n","        self.epochs = model_G_config.get_epochs()\n","        self.start_epoch = model_G_config.get_start_epoch()\n","        self.critic_iters = critic_iters\n","        self.device = device\n","        self.folder_checkpoint = folder_checkpoint\n","\n","    @staticmethod\n","    def loss_critic(model_G, model_C, img, noise, return_fake=False): \n","        img_fake = model_G(noise)\n","        output_real = model_C(img).mean()\n","        output_fake = model_C(img_fake).mean()\n","        loss = output_fake - output_real\n","        if return_fake:\n","            return loss, img_fake\n","        return loss\n","\n","    @staticmethod\n","    def loss_generative(model_G, model_C, noise, return_fake=False): \n","        img_fake = model_G(noise)\n","        loss = - model_C(img_fake).mean()\n","        if return_fake:\n","            return (loss, img_fake)\n","        return loss\n","\n","    def calc_gradient_penalty(self, model_C, real_img, fake_img, c=10):\n","        batch_size = real_img.size(0)\n","        alpha = torch.rand(batch_size, 1, 1, 1, device=self.device)\n","        alpha = alpha.expand_as(real_img)\n","        interpolated = alpha * real_img.data + ((1 - alpha) * fake_img.data)\n","        interpolated = autograd.Variable(interpolated, requires_grad=True).cuda(self.device)\n","        interpolated_val = model_C(interpolated)\n","        gradients = autograd.grad(\n","            interpolated_val, interpolated, grad_outputs=(\n","                torch.ones(interpolated_val.size()).cuda(self.device)),\n","                create_graph=True, retain_graph=True)[0]\n","        \n","        gradients = gradients.view(batch_size, -1)\n","        gradients_norm = torch.sqrt(torch.sum(gradients ** 2, dim=1) + EPS)\n","        gradient_penalty = c * ((gradients_norm - 1) ** 2).mean()\n","        return gradient_penalty\n","\n","\n","\n","    def get_model_config(self, name):\n","        if name == 'G':\n","            return self.model_G_config\n","        elif name == 'C':\n","            return self.model_C_config\n","\n","    def get_epochs(self):\n","        return self.epochs\n","\n","\n","    def plot_fake_imgs(self, fake_imgs, iters, folder_plot, figsize=(25,4)): # , figsize=(2,2)\n","        model_name = self.model_G_config.get_model_name()\n","        model_saved_name = model_name + f'_iters={iters+1}'\n","        full_path = os.path.join(folder_plot, f'fake_img_{model_saved_name}.png')\n","        plt.figure() # \n","        for i in range(fake_imgs.shape[0]):\n","            plt.subplot(1, fake_imgs.shape[0], i+1)\n","            plt.axis(\"off\")\n","            plt.title(f\"Fake Image {i+1}\")\n","            plt.imshow(fake_imgs[i].squeeze(0), cmap='gray')\n","        plt.savefig(full_path)\n","        plt.close()\n","\n","    def save_checkpoint(self, iters, model_config):\n","        model_name = model_config.get_model_name()\n","        model_saved_name = model_name + f'_iters={iters+1}'\n","        full_path = os.path.join(self.folder_checkpoint,\n","                                 f'{model_saved_name}.pth')\n","        torch.save({'model_state_dict': model_config.get_model().state_dict(),\n","                    'optimizer_state_dict': model_config.get_optimizer().state_dict(),\n","                    'scheduler_state_dict': model_config.get_scheduler().state_dict(),\n","                    'loss': model_config.get_loss(),\n","                    'iters':iters+1}, full_path)\n","        \n","\n","    def fit(self, train_loader, z_dim=100, k=1, real_label=1, folder_plot=''): #K = {1, 4, 5}, plot sandal\n","        fake_label = 1 - real_label\n","        model_G_config = self.model_G_config\n","        model_C_config = self.model_C_config\n","        model_G = model_G_config.get_model()\n","        model_C = model_C_config.get_model()\n","        device = self.device\n","        model_G = model_G.to(device)\n","        model_C = model_C.to(device)\n","        start_epoch, epochs = self.start_epoch, self.epochs\n","        opt_G = model_G_config.get_optimizer()\n","        opt_C = model_C_config.get_optimizer()\n","        sched_G =  model_G_config.get_scheduler()\n","        sched_C =  model_C_config.get_scheduler()\n","        loss_C = model_C_config.get_loss()\n","        loss_G = model_G_config.get_loss()\n","        \n","        iters = 0\n","        fixed_noise = create_noise(z_dim=z_dim, device=self.device, fixed=True)\n","\n","        for epoch in range(start_epoch, epochs):\n","            print(f'epochs {epoch +1} out of {epochs}')\n","            for i, (real_img, labels_img) in enumerate(train_loader):\n","                real_img = real_img.to(device)\n","                real_img_v = autograd.Variable(real_img).cuda(self.device)\n","                batch_size = real_img.size(0)\n","                opt_C.zero_grad()\n","                # labels = torch.full((batch_size,), real_label, device=self.device, dtype=torch.float)\n","                noise = create_noise(batch_size, z_dim, device=self.device)\n","                noise_v = autograd.Variable(noise).cuda(self.device) \n","                loss_c, fake_img = self.loss_critic(model_G, model_C, real_img_v, noise_v, return_fake=True)\n","\n","                loss_c_gp = loss_c + self.calc_gradient_penalty(model_C, real_img_v, fake_img)\n","                loss_c_gp.backward()\n","                # for p in model_C.parameters():\n","                #     p.data.clamp_(-1, 1)\n","                opt_C.step()\n","                \n","                #update generator after every critic_iters's critic updates\n","                if (iters+1) % self.critic_iters == 0:\n","                    opt_G.zero_grad()\n","                    # labels.fill_(real_label)  # fake labels are real for generator cost\n","                    noise = create_noise(batch_size, z_dim, device=self.device)\n","                    noise_v = autograd.Variable(noise).cuda(self.device)  # totally freeze mode_G\n","                    loss_g = self.loss_generative(model_G, model_C, noise_v)\n","                    loss_g.backward()\n","                    opt_G.step()\n","\n","                    loss_G.append(loss_g.item())\n","                    loss_C.append(loss_c_gp.item())\n","                # print(f'epoch = {epoch}\\tsave_every = {self.save_every}')\n","\n","                if self.save_model and (iters + 1) % self.save_every == 0:\n","                    print(f'iter = {iters+1} \\nloss_C: {loss_C[-1]}\\tLoss_G: {loss_G[-1]}')\n","                    with torch.no_grad():\n","                        fixed_fake_img = model_G(fixed_noise).detach().cpu().numpy()\n","                    \n","                    self.plot_fake_imgs(fixed_fake_img, iters, folder_plot)\n","                    self.save_checkpoint(iters, model_G_config)\n","                    self.save_checkpoint(iters, model_C_config)\n","                    \n","                iters += 1\n","\n","            sched_C.step()\n","            sched_G.step()\n","\n","        \n","    \n","    def print_loss(self, names=['Critic', 'Generator']):\n","        loss_C = self.model_C_config.get_loss()\n","        loss_G = self.model_G_config.get_loss()\n","        t = PrettyTable(['Epoch', f'Critic loss', f'Generator loss'])\n","        for i in range(len(loss_G)):\n","            t.add_row([i+1, loss_C[i], loss_G[i]])\n","        print(t)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y-Hnv3Ss5KQ6","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"hQC_emgr-e_T","colab_type":"text"},"source":["# **Plots**\n","* write to tensorboard when tuning on validation set\n","* make plots after choosing best hyperparams and check validation"]},{"cell_type":"code","metadata":{"id":"qy4L2dd8dDFp","colab_type":"code","colab":{}},"source":["# %load_ext tensorboard\n","# %reload_ext tensorboard\n","# %tensorboard --logdir=runs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OEJTcOJQZKcJ","colab_type":"code","colab":{}},"source":["# %kill 1135 #(or !kill 1135)\n","# !kill 438"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tIN9tgjpXehv","colab_type":"code","colab":{}},"source":["# writer for tuning hyperparameters (on validation set)\n","def plot_hyperparams(config_run, names=['Generator', 'Critic']): # start_epoch\n","    writer = SummaryWriter()\n","    model_G = config_run.get_model_config('G')\n","    model_C = config_run.get_model_config('C')\n","    loss_G = model_G.get_loss()\n","    loss_C = model_C.get_loss()\n","    models_name = f'G={model_G.get_model_name()}_C={model_C.get_model_name()}'\n","    epochs = len(loss_G)\n","    for i in range(epochs): # start_epoch\n","        tag_scalar_dict = {names[0]: loss_G[i], names[1]: loss_C[i]}\n","        writer.add_scalars(f'loss/{models_name}', tag_scalar_dict, i+1)\n","    writer.close()\n","\n","# save plots of best models\n","def plot_loss(config_run, folder_plot, save_plot=False, y_label='Loss', x_label='iterations'):  # start_epoch\n","    dict_loss = {'Generator': config_run.get_model_config('G').get_loss(),\n","                 'Critic': config_run.get_model_config('C').get_loss()}\n","    df_loss = pd.DataFrame(dict_loss)\n","    df_loss.set_index(pd.Index(range(1, df_loss.shape[0] + 1)), inplace=True)\n","    sns.lineplot(data=df_loss)\n","    title = 'WGAN-GP loss'\n","    plt.title(title)\n","    plt.ylim()\n","    plt.ylabel(y_label)\n","    plt.xlim(1,df_loss.shape[0])\n","    plt.xlabel(x_label)\n","    # plt.legend()\n","    plt.tight_layout()\n","    if not save_plot:\n","        plt.show()\n","    else:\n","        plt.savefig(os.path.join(folder_plot,f\"WGAN-GP_loss_{datetime.now().strftime('%y%m%d_%H%M%S')}.png\"))\n","        plt.close()\n","\n","def plot_imgs(imgs_real, imgs_fake, img_class, figsize=(25, 4), save_plot=False,\n","              folder_plot=None):\n","    \n","    fig = plt.figure(figsize=figsize)\n","    plt.subplot(1,2,1)\n","    plt.axis(\"off\")\n","    plt.title(f\"Real Images ({img_class})\")\n","    plt.imshow(np.transpose(imgs_real,(1,2,0)))\n","\n","    # Plot the fake images from the last epoch\n","    plt.subplot(1,2,2)\n","    plt.axis(\"off\")\n","    plt.title(f\"Fake Images ({img_class})\")\n","    plt.imshow(np.transpose(imgs_fake, (1,2,0)))\n","    if not save_plot:\n","        plt.show()\n","    else:\n","        plt.savefig(os.path.join(folder_plot,f\"WGAN-GP_imgs_{datetime.now().strftime('%y%m%d_%H%M%S')}.png\"))\n","        plt.close()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7wXYdLRpQRkt","colab_type":"text"},"source":["# main"]},{"cell_type":"code","metadata":{"id":"gWe8RrEFQmKt","colab_type":"code","colab":{}},"source":["DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","EPOCHS = 16 # or 16\n","FOLDER_CHECKPOINT = os.path.join(os.getcwd(), 'checkpoint')\n","FOLDER_PLOT = os.path.join(os.getcwd(), \"plots\")\n","os.makedirs(FOLDER_CHECKPOINT,exist_ok=True)\n","os.makedirs(FOLDER_PLOT,exist_ok=True)\n","EPS = np.finfo(float).eps\n","\n","def main(**args):\n","    torch.manual_seed(SEED)\n","    random.seed(SEED)\n","    save_model = args.get('save_model', True)\n","    scalar_plot = args.get('scalar_plot', False) \n","    make_plot = args.get('make_plot', False) \n","    save_plot = args.get('save_plot', False) \n","    \n","    file_saved_G_model = args.get('file_saved_G_model', '')\n","    file_saved_C_model = args.get('file_saved_C_model', '')\n","    trained_model_G_path = '' if file_saved_G_model == '' else \\\n","        os.path.join(os.getcwd(), FOLDER_CHECKPOINT, f'{file_saved_G_model}.pth')\n","    trained_model_C_path = '' if file_saved_C_model == '' else \\\n","        os.path.join(os.getcwd(), FOLDER_CHECKPOINT, f'{file_saved_C_model}.pth')\n","    dict_G_params = args.get('dict_G_params')\n","    config_G_params = HyperparamsConfig(dict_G_params)\n","    dict_C_params = args.get('dict_C_params')\n","    config_C_params = HyperparamsConfig(dict_C_params)\n","    train_loader = args.get('train_loader')\n","    save_every = args.get('save_every', 125)\n","    critic_iters = args.get('critic_iters', 1)\n","\n","    for G_config in config_G_params.create_configs():\n","        print(f'Generator hyperparams:\\n{G_config}')\n","        for C_config in config_C_params.create_configs():\n","            print(f'Critic hyperparams:\\n{C_config}')\n","            model_G = ModelRun(GeneratorWGANGP(), 'G', G_config, EPOCHS, DEVICE,\n","                                 trained_model_path=trained_model_G_path)\n","            model_C = ModelRun(Critic(), 'C', C_config, EPOCHS, DEVICE,\n","                               trained_model_path=trained_model_C_path)\n","            config_run = RunConfig(model_G, model_C, DEVICE, critic_iters, save_every, \n","                                   save_model, FOLDER_CHECKPOINT)\n","            \n","            config_run.fit(train_loader, folder_plot=FOLDER_PLOT)\n","            # config_run.print_loss()\n","            if scalar_plot:\n","                plot_hyperparams(config_run)\n","            if make_plot:\n","                plot_loss(config_run, FOLDER_PLOT, save_plot)\n","                # plot_imgs(imgs_real, imgs_fake, save_plot, folder_plot=FOLDER_PLOT)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Qyov_5uAWUOZ","colab_type":"text"},"source":["## Find best hyperparameters"]},{"cell_type":"code","metadata":{"id":"0KTpBtmKn1IV","colab_type":"code","colab":{}},"source":["# params = OrderedDict([\n","#                       ('optimizer_dict', [{'optim_name': 'SGD', 'optim_func': optim.SGD, 'optim_params': { 'momentum':0.9, 'nesterov': False}}]),\n","#                       ('lr', [0.001, 0.0001]), #add 0.0001?\n","#                       ('weight_decay', [0.0]) #\n","#                              ])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"y_YtqukZmaAC","colab_type":"code","colab":{}},"source":["# no dict_m_params\n","# main(dict_G_params=params, dict_D_params=params, train_loader=train_loader,\n","#      save_model=False, scalar_plot=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fWgUbS6SpdJ5","colab_type":"text"},"source":["## Run on test set with  best hyperparameter for each regularization"]},{"cell_type":"code","metadata":{"id":"Wsnz2Dt9iqsx","colab_type":"code","colab":{}},"source":["# params_G_best = OrderedDict([\n","#                       ('optimizer_dict', [{'optim_name': 'SGD', 'optim_func': optim.SGD, 'optim_params': { 'momentum':0.9, 'nesterov': False}}]),\n","#                       ('lr', [0.0001]), #add 0.0005 (best)?\n","#                       ('weight_decay', [0.0]) #0.0 (best)\n","#                              ])\n","\n","# params_C_best =  OrderedDict([\n","#                       ('optimizer_dict', [{'optim_name': 'SGD', 'optim_func': optim.SGD, 'optim_params': { 'momentum':0.9, 'nesterov': False}}]),\n","#                       ('lr', [0.0001]), #add 0.0001 (best)\n","#                       ('weight_decay', [0.0]) # 0.0 (Best)\n","#                              ])\n","\n","\n","params_G_best = OrderedDict([\n","                      ('optimizer_dict', [{'optim_name': 'Adam', 'optim_func': optim.Adam, 'optim_params': { 'betas':(0.5, 0.999)}}]),\n","                      ('lr', [1e-4]), #add 0.0005 (best)?\n","                      ('weight_decay', [1e-4]) #0.0 (best)\n","                             ])\n","\n","params_C_best =  OrderedDict([\n","                      ('optimizer_dict', [{'optim_name': 'Adam', 'optim_func': optim.Adam, 'optim_params': { 'betas':(0.5, 0.999)}}]),\n","                      ('lr', [1e-4]), #add 0.0001 (best)\n","                      ('weight_decay', [1e-4]) # 0.0 (Best)\n","                             ])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PzvqiGQiXemQ","colab_type":"code","outputId":"755de7a7-e329-444d-aac6-2bb2fdbc9239","executionInfo":{"status":"error","timestamp":1591507938384,"user_tz":-180,"elapsed":441320,"user":{"displayName":"Gal Kampel","photoUrl":"","userId":"12072246612200432478"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#take best hyperparams and run on test\n","main(dict_G_params=params_G_best, dict_C_params=params_C_best,\n","     train_loader=train_loader, make_plot=True, save_plot=True)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Generator hyperparams:\n","{'optimizer_dict': {'optim_name': 'Adam', 'optim_func': <class 'torch.optim.adam.Adam'>, 'optim_params': {'betas': (0.5, 0.999)}}, 'lr': 0.0001, 'weight_decay': 0.0001}\n","Critic hyperparams:\n","{'optimizer_dict': {'optim_name': 'Adam', 'optim_func': <class 'torch.optim.adam.Adam'>, 'optim_params': {'betas': (0.5, 0.999)}}, 'lr': 0.0001, 'weight_decay': 0.0001}\n","epochs 1 out of 16\n","iter = 125 \n","loss_C: 2.589787244796753\tLoss_G: -0.18314015865325928\n","iter = 250 \n","loss_C: 0.4999127984046936\tLoss_G: -0.26734036207199097\n","iter = 375 \n","loss_C: 0.06971049308776855\tLoss_G: -0.20553448796272278\n","iter = 500 \n","loss_C: 0.08037322759628296\tLoss_G: -0.20863434672355652\n","iter = 625 \n","loss_C: -0.1039629578590393\tLoss_G: -0.33421748876571655\n","iter = 750 \n","loss_C: 0.06561732292175293\tLoss_G: -0.43271175026893616\n","iter = 875 \n","loss_C: -0.11394032835960388\tLoss_G: -0.4479832053184509\n","iter = 1000 \n","loss_C: -0.09887576103210449\tLoss_G: -0.46318477392196655\n","iter = 1125 \n","loss_C: 0.16798847913742065\tLoss_G: -0.46343541145324707\n","iter = 1250 \n","loss_C: -0.06669710576534271\tLoss_G: -0.46780750155448914\n","iter = 1375 \n","loss_C: 0.027334749698638916\tLoss_G: -0.4664505422115326\n","iter = 1500 \n","loss_C: -0.18240191042423248\tLoss_G: -0.4665735960006714\n","iter = 1625 \n","loss_C: -0.14277589321136475\tLoss_G: -0.4659996032714844\n","iter = 1750 \n","loss_C: -0.1871395856142044\tLoss_G: -0.4655178487300873\n","iter = 1875 \n","loss_C: -0.18837480247020721\tLoss_G: -0.4645369052886963\n","epochs 2 out of 16\n","iter = 2000 \n","loss_C: -0.17703038454055786\tLoss_G: -0.4633389115333557\n","iter = 2125 \n","loss_C: -0.14818322658538818\tLoss_G: -0.46105852723121643\n","iter = 2250 \n","loss_C: -0.14614735543727875\tLoss_G: -0.4591793417930603\n","iter = 2375 \n","loss_C: -0.21876445412635803\tLoss_G: -0.4578699469566345\n","iter = 2500 \n","loss_C: -0.19484712183475494\tLoss_G: -0.4563049077987671\n","iter = 2625 \n","loss_C: -0.2050173431634903\tLoss_G: -0.4541045129299164\n","iter = 2750 \n","loss_C: -0.20607903599739075\tLoss_G: -0.45112836360931396\n","iter = 2875 \n","loss_C: -0.1802087128162384\tLoss_G: -0.44850867986679077\n","iter = 3000 \n","loss_C: -0.17962409555912018\tLoss_G: -0.4471956193447113\n","iter = 3125 \n","loss_C: -0.2141391634941101\tLoss_G: -0.4446072578430176\n","iter = 3250 \n","loss_C: -0.22332023084163666\tLoss_G: -0.44206953048706055\n","iter = 3375 \n","loss_C: -0.21808308362960815\tLoss_G: -0.4402267336845398\n","iter = 3500 \n","loss_C: -0.22826407849788666\tLoss_G: -0.4374449551105499\n","iter = 3625 \n","loss_C: -0.22210335731506348\tLoss_G: -0.4350181519985199\n","iter = 3750 \n","loss_C: -0.22030287981033325\tLoss_G: -0.4324207007884979\n","epochs 3 out of 16\n","iter = 3875 \n","loss_C: -0.22481109201908112\tLoss_G: -0.430144727230072\n","iter = 4000 \n","loss_C: -0.2451535165309906\tLoss_G: -0.42825838923454285\n","iter = 4125 \n","loss_C: -0.24484971165657043\tLoss_G: -0.42568206787109375\n","iter = 4250 \n","loss_C: -0.27691349387168884\tLoss_G: -0.4231696128845215\n","iter = 4375 \n","loss_C: -0.25501492619514465\tLoss_G: -0.42005661129951477\n","iter = 4500 \n","loss_C: -0.2804989218711853\tLoss_G: -0.41802263259887695\n","iter = 4625 \n","loss_C: -0.268223375082016\tLoss_G: -0.41591787338256836\n","iter = 4750 \n","loss_C: -0.2088136374950409\tLoss_G: -0.41322532296180725\n","iter = 4875 \n","loss_C: -0.29598966240882874\tLoss_G: -0.41091853380203247\n","iter = 5000 \n","loss_C: -0.29050132632255554\tLoss_G: -0.40846338868141174\n","iter = 5125 \n","loss_C: -0.29671043157577515\tLoss_G: -0.40616583824157715\n","iter = 5250 \n","loss_C: -0.2600635588169098\tLoss_G: -0.40379223227500916\n","iter = 5375 \n","loss_C: -0.27737557888031006\tLoss_G: -0.4011545777320862\n","iter = 5500 \n","loss_C: -0.2778500020503998\tLoss_G: -0.39811861515045166\n","iter = 5625 \n","loss_C: -0.28966400027275085\tLoss_G: -0.39635172486305237\n","epochs 4 out of 16\n","iter = 5750 \n","loss_C: -0.26735231280326843\tLoss_G: -0.39493411779403687\n","iter = 5875 \n","loss_C: -0.29769963026046753\tLoss_G: -0.3918631076812744\n","iter = 6000 \n","loss_C: -0.27674081921577454\tLoss_G: -0.3893078565597534\n","iter = 6125 \n","loss_C: -0.27907437086105347\tLoss_G: -0.38688725233078003\n","iter = 6250 \n","loss_C: -0.2879449129104614\tLoss_G: -0.3844761848449707\n","iter = 6375 \n","loss_C: -0.3041616380214691\tLoss_G: -0.3821665346622467\n","iter = 6500 \n","loss_C: -0.2707363963127136\tLoss_G: -0.3798869848251343\n","iter = 6625 \n","loss_C: -0.2595614194869995\tLoss_G: -0.37731820344924927\n","iter = 6750 \n","loss_C: -0.30616652965545654\tLoss_G: -0.374961793422699\n","iter = 6875 \n","loss_C: -0.33511999249458313\tLoss_G: -0.37288010120391846\n","iter = 7000 \n","loss_C: -0.28536295890808105\tLoss_G: -0.37061935663223267\n","iter = 7125 \n","loss_C: -0.29899218678474426\tLoss_G: -0.3682324290275574\n","iter = 7250 \n","loss_C: -0.305949866771698\tLoss_G: -0.36602136492729187\n","iter = 7375 \n","loss_C: -0.3348758816719055\tLoss_G: -0.36349180340766907\n","iter = 7500 \n","loss_C: -0.3196861445903778\tLoss_G: -0.3610588312149048\n","epochs 5 out of 16\n","iter = 7625 \n","loss_C: -0.32040244340896606\tLoss_G: -0.3589242696762085\n","iter = 7750 \n","loss_C: -0.20707429945468903\tLoss_G: -0.35676002502441406\n","iter = 7875 \n","loss_C: -0.3258879482746124\tLoss_G: -0.354824960231781\n","iter = 8000 \n","loss_C: -0.34646162390708923\tLoss_G: -0.35246148705482483\n","iter = 8125 \n","loss_C: -0.3248496651649475\tLoss_G: -0.350458025932312\n","iter = 8250 \n","loss_C: -0.35172387957572937\tLoss_G: -0.347921758890152\n","iter = 8375 \n","loss_C: -0.2878374457359314\tLoss_G: -0.34630337357521057\n","iter = 8500 \n","loss_C: -0.33172670006752014\tLoss_G: -0.3443543314933777\n","iter = 8625 \n","loss_C: -0.3088234066963196\tLoss_G: -0.34213992953300476\n","iter = 8750 \n","loss_C: -0.34727051854133606\tLoss_G: -0.3402590751647949\n","iter = 8875 \n","loss_C: -0.34842804074287415\tLoss_G: -0.3373851776123047\n","iter = 9000 \n","loss_C: -0.3481246829032898\tLoss_G: -0.3361336588859558\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-a31805449d41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#take best hyperparams and run on test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m main(dict_G_params=params_G_best, dict_C_params=params_C_best,\n\u001b[0;32m----> 3\u001b[0;31m      train_loader=train_loader, make_plot=True, save_plot=True)\n\u001b[0m","\u001b[0;32m<ipython-input-14-ccc96d84dba4>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(**args)\u001b[0m\n\u001b[1;32m     38\u001b[0m                                    save_model, FOLDER_CHECKPOINT)\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mconfig_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolder_plot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFOLDER_PLOT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0;31m# config_run.print_loss()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mscalar_plot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-12-6341ea0b4035>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_loader, z_dim, k, real_label, folder_plot)\u001b[0m\n\u001b[1;32m    134\u001b[0m                     \u001b[0mopt_G\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m                     \u001b[0mloss_G\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_g\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m                     \u001b[0mloss_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_c_gp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0;31m# print(f'epoch = {epoch}\\tsave_every = {self.save_every}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"9p4sFgxlprIy","colab_type":"text"},"source":["## Test pre-trained model\n","* load Generator\n","* load real images and noise samples\n","* print results\n","\n"]},{"cell_type":"code","metadata":{"id":"6DENADaS7WzC","colab_type":"code","colab":{}},"source":["# ImageSize = 32 #warp input image s.t. height=width=32 \n","def load_FMNIST_dataset(transform, train=True):\n","    return torchvision.datasets.FashionMNIST(\n","                root = '~/.pytorch/F_MNIST_data/',\n","                train = train,\n","                download = True,\n","                transform = transform\n","            )\n","# each channel is normalized to be in the range [-1,1] (only one channel (grayscale))\n","TRANSFORM = transforms.Compose([\n","                                transforms.ToTensor(),\n","                                transforms.Normalize((0.5,), (0.5,))] \n","                               )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UVrst0yH7YaB","colab_type":"code","colab":{}},"source":["BATCH_SIZE_TEST = 1\n","# dataset_tmp = load_FMNIST_dataset(TRANSFORM)\n","# training_set, validation_set = torch.utils.data.random_split(dataset_tmp, [50000, 10000])\n","# training_set = load_FMNIST_dataset(TRANSFORM)\n","# train_loader = torch.utils.data.DataLoader(training_set, batch_size = BATCH_SIZE, shuffle=True)\n","# val_loader = torch.utils.data.DataLoader(validation_set, batch_size = BATCH_SIZE, shuffle=False)\n","test_set = load_FMNIST_dataset(TRANSFORM, train=False)\n","test_loader = torch.utils.data.DataLoader(test_set, batch_size = BATCH_SIZE_TEST, shuffle=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mdHWc5KnfuRY","colab_type":"code","colab":{}},"source":["DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","EPOCHS = 30 #the best epoch to print\n","FOLDER_MODEL = os.path.join(os.getcwd(), FOLDER_CHECKPOINT)\n","FOLDER_PLOT = os.path.join(os.getcwd(), \"plots\")\n","\n","def load_imgs(path_imgs):\n","    checkpoint = torch.load(path_imgs)\n","    noise = checkpoint['noise']\n","    img = checkpoint['img']\n","    img_class = checkpoint['img_class']\n","    iters = checkpoint['iters']\n","    return noise, img, img_class, iters\n","    \n","\n","def get_generated_img(**args): \n","    file_saved_G_model = args.get('file_saved_G_model', '')\n","    trained_model_G_path = os.path.join(FOLDER_MODEL, f'{file_saved_G_model}.pth')\n","    model_G_params = args.get('model_G_params')\n","    img_file = args.get('img_file', '')\n","    test_loader = args.get('test_loader')\n","    class_labels = args.get('class_labels', [])\n","    path_img = os.path.join(FOLDER_MODEL, f'{img_file}.pth')\n","    noise, real_imgs, img_class, epoch = load_imgs(path_img)\n","\n","    model_G = ModelRun(Generator(), 'G', model_G_params, epoch, device,\n","                            trained_model_G_path='')\n","    model_pretrained_G = model_G.get_model()\n","    with torch.no_grad():\n","        fixed_fake_img = model_G(fixed_noise).detach().cpu()\n","    \n","    fake_imgs = np.concatenate(fake_imgs)\n","    real_imgs = get_real_imgs(test_loader, class_labels)\n","    real_imgs = np.concatenate(real_imgs)\n","    plot_imgs(real_imgs, fake_imgs, figsize=(4, 4), save_plot=True,\n","              folder_plot=FOLDER_PLOT)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TqkO1iUp7b5L","colab_type":"code","colab":{}},"source":["\n","get_generated_img(file_saved_G_model='',model_G_params='',img_file='' )"],"execution_count":0,"outputs":[]}]}