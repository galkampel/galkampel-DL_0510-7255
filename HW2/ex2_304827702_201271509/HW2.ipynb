{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HW2.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"RCW4Re086f1K","colab_type":"text"},"source":["# **HW2- Predicting next word with GRU and LSTM**"]},{"cell_type":"code","metadata":{"id":"yFBl9avc-q8T","colab_type":"code","outputId":"1665d7c1-6b73-47ea-bd27-b117fab8a126","executionInfo":{"status":"ok","timestamp":1589177886553,"user_tz":-180,"elapsed":2134,"user":{"displayName":"Gal Kampel","photoUrl":"","userId":"12072246612200432478"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib\n","import matplotlib.pyplot as plt\n","from tqdm import trange\n","from datetime import datetime\n","from collections import OrderedDict, Counter\n","from itertools import product\n","from prettytable import PrettyTable\n","import os\n","import random"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"c7365J3P-rAv","colab_type":"code","colab":{}},"source":["import torch\n","import torchvision\n","from torch import nn, optim\n","from torch.optim import lr_scheduler\n","from torch.utils.data import DataLoader\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms\n","from torch.utils.tensorboard import SummaryWriter\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-fKxUwl3-rCH","colab_type":"code","outputId":"bab19438-79b6-4de4-98ba-96f8dd0bf203","executionInfo":{"status":"ok","timestamp":1589177893706,"user_tz":-180,"elapsed":4940,"user":{"displayName":"Gal Kampel","photoUrl":"","userId":"12072246612200432478"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["SEED = 0\n","torch.manual_seed(SEED)\n","random.seed(SEED)\n","torch.cuda.is_available()"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"Ctux_6Kd8lUF","colab_type":"code","outputId":"11701dc2-47be-40b6-bdef-70c10d2e3fdd","executionInfo":{"status":"ok","timestamp":1589177918902,"user_tz":-180,"elapsed":29272,"user":{"displayName":"Gal Kampel","photoUrl":"","userId":"12072246612200432478"}},"colab":{"base_uri":"https://localhost:8080/","height":143}},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","ROOT_PATH = '/content/drive/My Drive/DL-Raja/HW2/ex2_304827702_201271509/'\n","os.chdir(ROOT_PATH)\n","os.getcwd()"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["'/content/drive/My Drive/DL-Raja/HW2/ex2_304827702_201271509'"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"T1i2vXFGWlhN","colab_type":"text"},"source":["## **Load PTB dataset**"]},{"cell_type":"code","metadata":{"id":"85jFkjWYmY_b","colab_type":"code","colab":{}},"source":["FOLDER_DATA = os.path.join(os.getcwd(), 'PTB')\n","def load_dataset(folder_path, file_name):\n","    full_path = os.path.join(folder_path, file_name)\n","    with open(full_path, 'r') as f:\n","        return f.readlines() # or  f.read() (character-level)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vOjraNF0owQx","colab_type":"code","colab":{}},"source":["training_file = load_dataset(FOLDER_DATA, 'ptb.train.txt')\n","validation_file = load_dataset(FOLDER_DATA, 'ptb.valid.txt')\n","test_file = load_dataset(FOLDER_DATA, 'ptb.test.txt')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kGaHDoQRsL8U","colab_type":"code","outputId":"31f5a280-d642-42d7-bcc1-f9ce875d9795","executionInfo":{"status":"ok","timestamp":1589178033051,"user_tz":-180,"elapsed":1721,"user":{"displayName":"Gal Kampel","photoUrl":"","userId":"12072246612200432478"}},"colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["print(f'#sentences in train = {len(training_file)}')\n","print(f'#sentences in validation = {len(validation_file)}')\n","print(f'#sentences in test = {len(test_file)}')"],"execution_count":7,"outputs":[{"output_type":"stream","text":["#sentences in train = 42068\n","#sentences in validation = 3370\n","#sentences in test = 3761\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5HlVWcHtgXuE","colab_type":"text"},"source":["## *Tokenizer*- tokenizing datasets (for embeddings layer)"]},{"cell_type":"code","metadata":{"id":"jWhs5XY_eSlT","colab_type":"code","colab":{}},"source":["class Tokenizer: #create vocab\n","    def __init__(self, file):\n","        self.file = file\n","        self.vocab_to_int = None\n","\n","    def get_vocab_to_int(self):\n","        return self.vocab_to_int\n","\n","    def create_vocab(self):\n","        words = []\n","        for row in self.file:\n","            sentence = row[1:].split(' ')\n","            sentence[-1] = '<eos>' # replace '\\n' with <eos>\n","            words.extend(sentence)\n","\n","        counts = Counter(words)\n","        vocab = sorted(counts, key=counts.get, reverse=True)\n","        vocab_to_int = {word: idx for idx, word in enumerate(vocab, 1)}\n","        self.vocab_to_int = vocab_to_int\n","\n","    def file2token(self, file):\n","        vocab_to_int = self.vocab_to_int\n","        tokens = []\n","        for sentence in file:\n","            words = sentence[1:].split(' ')\n","            words[-1] = '<eos>'\n","            tokens.extend([vocab_to_int[word] for word in words])\n","        return tokens"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"A4eraWg8cum8","colab_type":"code","colab":{}},"source":["# get all words (from training file)\n","tokenizer = Tokenizer(training_file)\n","tokenizer.create_vocab()\n","training_token = tokenizer.file2token(training_file)\n","validation_token = tokenizer.file2token(validation_file)\n","test_token = tokenizer.file2token(test_file)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LzOPPOHAqKyh","colab_type":"text"},"source":["## Create \"Dataloader\""]},{"cell_type":"code","metadata":{"id":"lSLxm_vxryrT","colab_type":"code","colab":{}},"source":["BATCH_SIZE = 16\n","SEQ_LEN = 35\n","def create_dataset(data_token, batch_size=20, seq_len=20):\n","    chunk_size = batch_size * seq_len\n","    n_batch = (len(data_token) - 1) // (batch_size * seq_len)\n","    i_start = 0\n","    dataset = []\n","    for i_batch in range(n_batch):\n","        x_batch = np.array(data_token[i_start:i_start + chunk_size]).reshape((batch_size, seq_len))\n","        y_batch = np.array(data_token[(i_start + 1):(i_start + 1) + chunk_size]).reshape((batch_size, seq_len))\n","        dataset.append((x_batch, y_batch))\n","        i_start += chunk_size\n","    return dataset\n","\n","\n","def create_data_loader(dataset):\n","    idxes = list(range(len(dataset)))\n","    random.shuffle(idxes)\n","    for i in idxes:\n","        X_batch, y_batch = dataset[i]\n","        yield torch.from_numpy(X_batch).type(torch.LongTensor), torch.from_numpy(y_batch).type(torch.LongTensor)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"L-1IqMpkjJI6","colab_type":"code","colab":{}},"source":["training_set = create_dataset(training_token, BATCH_SIZE, SEQ_LEN)\n","validation_set = create_dataset(validation_token, BATCH_SIZE, SEQ_LEN)\n","test_set = create_dataset(test_token, BATCH_SIZE, SEQ_LEN)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DmjnRxOgJB4t","colab_type":"text"},"source":["#**Word predictor class**"]},{"cell_type":"code","metadata":{"id":"KTB6Rv1qFNZ5","colab_type":"code","colab":{}},"source":["class WordPredictor(nn.Module):\n","    def __init__(self, **params):\n","        super(WordPredictor, self).__init__()\n","        self.n_layers = params[\"n_layers\"]\n","        self.hidden_dim = params[\"hidden_dim\"]\n","        self.embedding_dim = params[\"embedding_dim\"]\n","        self.rnn_type = params[\"rnn_type\"]\n","        self.dropout = nn.Dropout(params.get(\"dropout\", 0))\n","        self.embeddings = nn.Embedding(params[\"vocab_size\"], params[\"embedding_dim\"])\n","        # self.init_embedding_layer()\n","        self.rnn_layers = self.get_rnn_layers(params)\n","        # self.init_rnn_layers()\n","        # self.classifier = nn.Linear(params[\"hidden_dim\"], params[\"vocab_size\"])\n","        self.classifier = nn.Sequential(\n","            nn.Linear(params[\"hidden_dim\"], params[\"hidden_dim\"]),\n","            nn.ReLU(),\n","            nn.Linear(params[\"hidden_dim\"], params[\"vocab_size\"])\n","        ) if params.get(\"use_seq\", False) \\\n","        else nn.Linear(params[\"hidden_dim\"], params[\"vocab_size\"])\n","\n","    def get_rnn_type(self):\n","        return self.rnn_type\n","\n","    def get_rnn_layers(self, params):\n","        if self.rnn_type == \"lstm\":\n","            return nn.LSTM(self.embedding_dim, self.hidden_dim, self.n_layers, \n","                           dropout=params.get(\"dropout\", 0), batch_first=True)\n","        else:\n","            return nn.GRU(self.embedding_dim, self.hidden_dim, self.n_layers, \n","                           dropout=params.get(\"dropout\", 0), batch_first=True)\n","\n","    def init_hidden(self, batch_size, device):\n","        ''' Initializes hidden state '''\n","        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n","        # initialized to zero, for hidden state and cell state of LSTM\n","        weight = next(self.parameters()).data\n","        hidden = None\n","        if self.rnn_type == 'lstm':\n","            hidden = (\n","                weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device),\n","                weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device))\n","        elif self.rnn_type == 'gru':\n","            hidden = \\\n","            weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device)\n","\n","        return hidden\n","\n","    def init_embedding_layer(self, init_weights=0.1):\n","        for name, param in self.embeddings.named_parameters():\n","            if 'weight' in name:\n","                param.data.uniform_(-init_weights, init_weights)\n","                \n","    \n","    def forward(self, x, hidden):\n","        \"\"\"\n","        Perform a forward pass of our model on some input and hidden state.\n","        \"\"\"\n","        batch_size = x.size(0)\n","        # embeddings and lstm_out\n","        x = x.long()\n","        embeds_out = self.dropout(self.embeddings(x))\n","        # embeds_out = self.embeddings(x)\n","        rnn_out, hidden = self.rnn_layers(embeds_out, hidden)\n","        # stack up lstm outputs\n","        # print(f'rnn_out.shape before reshape = {rnn_out.shape}')\n","        rnn_out = rnn_out.contiguous().view(-1, self.hidden_dim)\n","        # print(f'rnn_out.shape after reshape = {rnn_out.shape}')\n","        # dropout and fully-connected layer\n","        # dropout_out = self.dropout(rnn_out)\n","        # logits = self.classifier(dropout_out)\n","        logits = self.classifier(rnn_out)\n","        return logits, hidden"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A-g31FnYBiqt","colab_type":"text"},"source":["## Hyperparameters generator"]},{"cell_type":"code","metadata":{"id":"7Cdpk2pbEKJX","colab_type":"code","colab":{}},"source":["# optimizers (SGD (nesterov=True))\n","#lrs=[1, 0.5, 0.4, 0.25] ,dropouts=[0, 0.1, 0.3, 0.5], (w_ds=[1e-3, 1e-4, 1e-5])\n","class HyperparamsConfig:\n","    def __init__(self, hyperparams_dict): \n","        self.hyperparams_dict = hyperparams_dict\n","        self.hyperparams_names = list(hyperparams_dict.keys())\n","\n","    def create_configs(self):\n","        h_params_names = self.hyperparams_names\n","        for h_params_vals in product(*[h_params  for h_params in self.hyperparams_dict.values()]):\n","            yield {h_params_name: h_params_vals[i] for i, h_params_name in enumerate(h_params_names)}\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m2TvlcVrBrcV","colab_type":"text"},"source":["## Model configuration per run \n","* Create  a new WordPredictor model acclording to specific configuration (if starting epoch=0)\n","* Enabing load saved model with its optimizer, scheduler and starting epoch"]},{"cell_type":"code","metadata":{"id":"u-8nPV76yRvL","colab_type":"code","colab":{}},"source":["class ModelRun:\n","    def __init__(self, config, params, epochs, device, trained_model_path=''):\n","        self.config = config\n","        self.epochs = epochs\n","        self.model_name = ''\n","        model_params = {param_name: param_val for param_name, param_val in params.items()}\n","        model_params['dropout'] = config.get('dropout', 0.0)\n","        self.model = WordPredictor(**model_params)\n","        self.device = device\n","        self.max_grad_norm = params.get('max_grad_norm', 5)\n","        self.start_epoch = 0\n","        self.optimizer = self.set_optimizer(params.get('rnn_type'))\n","        self.scheduler = lr_scheduler.CosineAnnealingLR(self.optimizer,epochs)\n","        self.dict_ppl = None\n","        if trained_model_path != '' and os.path.exists(trained_model_path):\n","            self.load_model(trained_model_path)\n","    \n","    \n","    def set_optim_params(self, param_groups, params_dict):\n","        weight_decay = self.config.get('weight_decay', 0.0)\n","        if weight_decay > 0:\n","            params_dict['weight_decay'] = weight_decay\n","        for param_name, param_val in  params_dict.items():\n","            param_groups[param_name] = param_val\n","\n","\n","    def set_optimizer(self, rnn_type):\n","        model = self.model\n","        model.to(self.device)\n","        config = self.config\n","        optimizer_dict = config['optimizer_dict']\n","        optim_name = optimizer_dict['optim_name']\n","        self.set_model_name(optim_name, rnn_type)\n","        lr = self.config['lr']\n","        optimizer = optimizer_dict['optim_func'](model.parameters(), lr=lr)\n","        optimizer_params_dict = optimizer_dict['optim_params']\n","        self.set_optim_params(optimizer.param_groups[0], optimizer_params_dict)\n","        return optimizer\n","\n","\n","    def set_model_name(self, optim_name, rnn_type):\n","        config = self.config\n","        lr = config.get('lr')\n","        weight_decay = config.get('weight_decay', 0.0) \n","        dropout = config.get('dropout', 0.0)\n","        self.model_name = f\"WordPredictor_{rnn_type}_optimizer={optim_name}_\" \\\n","                          f\"lr={lr}_dropout={dropout}_weight_decay={weight_decay}\"\n","\n","\n","    def get_model(self):\n","        return self.model\n","         \n","    def get_device(self):\n","        return self.device\n","\n","    def get_max_grad_norm(self):\n","        return self.max_grad_norm\n","\n","    def get_optimizer(self):\n","        return self.optimizer\n","    \n","    def get_scheduler(self):\n","        return self.scheduler\n","\n","    def get_model_name(self):\n","        return self.model_name\n","    \n","    def get_dict_ppl(self):\n","        return self.dict_ppl\n","\n","    def get_epochs(self):\n","        return self.epochs\n","\n","    def get_start_epoch(self):\n","        return self.start_epoch\n","         \n","    def load_model(self, path_model):\n","        checkpoint = torch.load(path_model)\n","        self.model.load_state_dict(checkpoint['model_state_dict'])\n","        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","        self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n","        self.dict_ppl = checkpoint['dict_ppl']\n","        self.start_epoch = checkpoint['epoch']\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l48ZrK6fCfiE","colab_type":"text"},"source":["## Run configuration\n","* fit and evaluate on validation\n","* scalar plot (tensorboard) and train-validation plot\n","* enable saving the model during training"]},{"cell_type":"code","metadata":{"id":"z_y-B4Jiadcv","colab_type":"code","colab":{}},"source":["class RunConfig:\n","    def __init__(self, model_config, save_model=True,\n","                 folder_checkpoint=''):\n","        self.model_config = model_config\n","        self.device = model_config.get_device()\n","        self.criterion = nn.CrossEntropyLoss()\n","        self.save_model = save_model\n","        self.model = model_config.get_model()\n","        self.optimizer = model_config.get_optimizer()\n","        self.scheduler = model_config.get_scheduler()\n","        self.epochs = model_config.get_epochs()\n","        self.max_grad_norm = model_config.get_max_grad_norm()\n","        self.start_epoch = model_config.get_start_epoch()\n","        self.model_name = model_config.get_model_name()\n","        self.folder_checkpoint = folder_checkpoint\n","        self.dict_ppl = model_config.get_dict_ppl()\n","        if self.dict_ppl is None:\n","            self.dict_ppl = OrderedDict([\n","                                         ('train',[]),\n","                                         ('validation', [])\n","                                         ]) \n","    @staticmethod\n","    def detach_hidden(model, h):\n","        if model.get_rnn_type() == 'lstm':\n","            return tuple([el.data for el in h])  # tuple([el.detach() for el in h])\n","        elif model.get_rnn_type() == 'gru':\n","            return h.data # h.detach()\n","    \n","    def get_dict_ppl(self):\n","        return self.dict_ppl\n","\n","    def get_model_name(self):\n","        return self.model_name\n","\n","    def get_epochs(self):\n","        return self.epochs\n","    \n","    def evaluate(self, eval_loader, batch_size, lst_ppl):\n","        device = self.device\n","        with torch.no_grad():\n","            self.model.eval()\n","            h = self.model.init_hidden(batch_size, device)\n","            running_loss = 0.0\n","            eval_loader_size = 0\n","            for eval_seq, eval_labels in eval_loader:\n","                eval_seq, eval_labels = eval_seq.to(device), eval_labels.to(device)\n","                logits, h = self.model(eval_seq, h) \n","                h = self.detach_hidden(self.model, h)\n","                loss = self.criterion(logits, eval_labels.view(-1))\n","                running_loss += loss.item()\n","                # ps = torch.exp(log_ps)\n","                # top_ps, top_class = ps.topk(1, dim=1)\n","                # equality = top_class == eval_labels.view(*top_class.shape)\n","                eval_loader_size += 1\n","            ppl = np.exp(running_loss / eval_loader_size)\n","            lst_ppl.append(ppl)\n","        h = self.detach_hidden(self.model, h) # new addition 10.5\n","        self.model.train()\n","\n","\n","    def save_checkpoint(self, epoch):\n","        model_saved_name = self.model_name + f'_epoch={epoch+1}'\n","        full_path = os.path.join(self.folder_checkpoint,\n","                                 f'{model_saved_name}.pth')\n","        torch.save({'model_state_dict': self.model.state_dict(),\n","                    'optimizer_state_dict': self.optimizer.state_dict(),\n","                    'scheduler_state_dict': self.scheduler.state_dict(),\n","                    'dict_ppl': self.dict_ppl,\n","                    'epoch':{epoch+1}}, full_path)\n","        \n","\n","    def fit(self, training_set, validation_set, batch_size):\n","        names = list(self.dict_ppl.keys())\n","        lst_ppl_train = self.dict_ppl[names[0]]\n","        lst_ppl_val = self.dict_ppl[names[1]]\n","        device = self.device\n","        model = self.model.to(device)\n","        start_epoch, epochs = self.start_epoch, self.epochs\n","        with trange(start_epoch, epochs, desc=\"Epochs\", disable=False) as te:\n","            model.train()\n","            for epoch in te:\n","                h = model.init_hidden(batch_size, self.device)\n","                running_loss = 0.0\n","                tr_loader_size = 0\n","                for tr_seq, tr_labels in create_data_loader(training_set):\n","                    tr_seq, tr_labels = tr_seq.to(device), tr_labels.to(device)\n","                    self.optimizer.zero_grad()\n","                    logits, h = model(tr_seq, h) \n","                    h = self.detach_hidden(model, h)\n","                    loss = self.criterion(logits, tr_labels.view(-1))\n","                    loss.backward()\n","                    nn.utils.clip_grad_norm_(model.parameters(), self.max_grad_norm)\n","                    self.optimizer.step()\n","                    running_loss += loss.item()\n","                    tr_loader_size += 1\n","                    # ps = torch.exp(log_ps)\n","                    # top_ps, top_class = ps.topk(1, dim=1)\n","                    # equality = top_class == tr_labels.view(*top_class.shape)\n","                    # total_loss += torch.mean(equality.type(torch.FloatTensor)).item()\n","                # print(f'tr_loader_size = {tr_loader_size}')\n","                ppl_train = np.exp(running_loss / tr_loader_size)\n","                te.set_postfix(PPL=ppl_train) \n","                self.evaluate(create_data_loader(training_set), batch_size, lst_ppl_train)\n","                self.evaluate(create_data_loader(validation_set), batch_size, lst_ppl_val)\n","\n","                self.scheduler.step()   \n","\n","                if self.save_model and ((epoch >= 2 and lst_ppl_val[-1] < lst_ppl_val[-2]) or (epoch == epochs-1)):\n","                    self.save_checkpoint(epoch)\n","    \n","    def print_ppls(self): \n","        names = list(self.dict_ppl.keys())\n","        lst_ppl_train = self.dict_ppl[names[0]]\n","        lst_ppl_val = self.dict_ppl[names[1]]\n","        t = PrettyTable(['Epoch', f'{names[0]} ppl', f'{names[1]} ppl'])\n","        for i in range(len(lst_ppl_train)):\n","            t.add_row([i+1, lst_ppl_train[i], lst_ppl_val[i]])\n","        print(t)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hQC_emgr-e_T","colab_type":"text"},"source":["# **Plots**\n","* write to tensorboard when tuning on validation set\n","* make plots after choosing best hyperparams and check validation"]},{"cell_type":"code","metadata":{"id":"qy4L2dd8dDFp","colab_type":"code","colab":{}},"source":["# %load_ext tensorboard\n","# %reload_ext tensorboard\n","# %tensorboard --logdir=runs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OEJTcOJQZKcJ","colab_type":"code","colab":{}},"source":["# %kill 1135 #(or !kill 1135)\n","# !kill 438"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tIN9tgjpXehv","colab_type":"code","colab":{}},"source":["# writer for tuning hyperparameters (on validation set)\n","def plot_hyperparams(dict_ppl, model_name): # start_epoch\n","    writer = SummaryWriter()\n","    names = list(dict_ppl.keys())\n","    ppl_train = dict_ppl[names[0]]\n","    ppl_val = dict_ppl[names[1]]\n","    epochs = len(ppl_train)\n","    for i in range(epochs): # start_epoch\n","        tag_scalar_dict = {names[0]: ppl_train[i], names[1]: ppl_val[i]}\n","        writer.add_scalars(f'perplexity/{model_name}', tag_scalar_dict, i+1)\n","    writer.close()\n","\n","# save plots of best models\n","def plot_perplexity(dict_ppl, model_name, folder_plot, \n","                  y_label='Perplexity', x_label='Epochs'):  # start_epoch\n","    df_ppl = pd.DataFrame(dict_ppl)\n","    df_ppl.set_index(pd.Index(range(1, df_ppl.shape[0] + 1)), inplace=True)\n","    sns.lineplot(data=df_ppl)\n","    title = model_name.replace('_lr=','\\nlr=')\n","    plt.title(title)\n","    plt.ylim()\n","    plt.ylabel(y_label)\n","    plt.xlim(1,df_ppl.shape[0])\n","    plt.xlabel(x_label)\n","    # plt.legend()\n","    plt.tight_layout()\n","    plt.savefig(os.path.join(folder_plot,f\"{model_name}_{datetime.now().strftime('%y%m%d_%H%M%S')}.png\"))\n","    plt.close()\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7wXYdLRpQRkt","colab_type":"text"},"source":["# main"]},{"cell_type":"code","metadata":{"id":"gWe8RrEFQmKt","colab_type":"code","colab":{}},"source":["DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","EPOCHS = 30\n","FOLDER_CHECKPOINT = os.path.join(os.getcwd(), 'checkpoint')\n","FOLDER_PLOT = os.path.join(os.getcwd(), \"plots\")\n","os.makedirs(FOLDER_CHECKPOINT,exist_ok=True)\n","os.makedirs(FOLDER_PLOT,exist_ok=True)\n","\n","\n","def main(**args):\n","    torch.manual_seed(SEED)\n","    random.seed(SEED)\n","    # check_test = args.get('check_test', False)\n","    save_model = args.get('save_model', True)\n","    # dir_model = args.get('dir_model', '')\n","    # make_plot = args.get('make_plot', True)  \n","    scalar_plot = args.get('scalar_plot', False) \n","    tr_val_plot = args.get('tr_val_plot', False) \n","    \n","    file_saved_model = args.get('file_saved_model', '')\n","    trained_model_path = '' if file_saved_model == '' else \\\n","        os.path.join(os.getcwd(), FOLDER_CHECKPOINT, f'{file_saved_model}.pth')\n","    dict_h_params = args.get('dict_h_params')\n","    config_h_params = HyperparamsConfig(dict_h_params)\n","    dict_m_params = args.get('dict_m_params', None)\n","    assert isinstance(dict_m_params, dict) , \"model_params should be a dict of params to WordPredictor class\"\n","    config_m_params = HyperparamsConfig(dict_m_params)\n","    training_set = args.get('training_set')\n","    validation_set = args.get('validation_set')\n","\n","    for h_config in config_h_params.create_configs():\n","        print(f'hyper params config:\\n{h_config}')\n","        for m_config in config_m_params.create_configs():\n","            print(f'model config:\\n{m_config}')\n","            model_run = ModelRun(h_config, m_config, EPOCHS, DEVICE, trained_model_path)\n","            config_run = RunConfig(model_run, save_model, FOLDER_CHECKPOINT)\n","            config_run.fit(training_set, validation_set, BATCH_SIZE)\n","            config_run.print_ppls()\n","            dict_ppl = config_run.get_dict_ppl()\n","            model_name = config_run.get_model_name()\n","            if scalar_plot:\n","                plot_hyperparams(dict_ppl, model_name)\n","            if tr_val_plot:\n","                plot_perplexity(dict_ppl, model_name, FOLDER_PLOT)\n","        \n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Qyov_5uAWUOZ","colab_type":"text"},"source":["## Find best hyperparameters using validation set for each regularization"]},{"cell_type":"code","metadata":{"id":"0KTpBtmKn1IV","colab_type":"code","colab":{}},"source":["params_no_reg = OrderedDict([\n","                             ('optimizer_dict', \n","                              [{'optim_name': 'SGD', 'optim_func': optim.SGD, 'optim_params': { 'momentum':0.9, 'nesterov': True}}]),\n","                             ('lr', [0.5]), #best 0.5\n","                             ('weight_decay', [8e-5]), #best 8e-5\n","                             ('dropout', [0.0]),\n","                             ('use_seq', [False])\n","                             ])\n","\n","params_dropout = OrderedDict([\n","                              ('optimizer_dict',\n","                               [{'optim_name': 'SGD', 'optim_func': optim.SGD, 'optim_params': { 'momentum':0.9, 'nesterov': False}}]),\n","                              ('lr', [0.5]),\n","                             ('weight_decay', [6e-5]),\n","                             ('dropout', [0.2]), \n","                             ('use_seq', [False])\n","                             ])\n","\n","\n","params_model = OrderedDict([\n","                            ('vocab_size', [10000]), ('hidden_dim', [200]),\n","                            ('embedding_dim', [200]), ('max_grad_norm', [5]), \n","                            ('rnn_type', ['lstm', 'gru']), ('n_layers', [2])\n","                            ])\n","\n","# [{'optim_name': 'Adam', 'optim_func': optim.Adam, 'optim_params': {}}]),"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"y_YtqukZmaAC","colab_type":"code","outputId":"cd657c05-7d2f-4313-cbca-0b652b67f146","executionInfo":{"status":"ok","timestamp":1589179381563,"user_tz":-180,"elapsed":1340722,"user":{"displayName":"Gal Kampel","photoUrl":"","userId":"12072246612200432478"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["main(dict_h_params=params_no_reg,dict_m_params=params_model,\n","     training_set=training_set, validation_set=validation_set, scalar_plot=True)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["hyper params config:\n","{'optimizer_dict': {'optim_name': 'SGD', 'optim_func': <class 'torch.optim.sgd.SGD'>, 'optim_params': {'momentum': 0.9, 'nesterov': True}}, 'lr': 0.5, 'weight_decay': 8e-05, 'dropout': 0.0, 'use_seq': False}\n","model config:\n","{'vocab_size': 10000, 'hidden_dim': 200, 'embedding_dim': 200, 'max_grad_norm': 5, 'rnn_type': 'lstm', 'n_layers': 2}\n"],"name":"stdout"},{"output_type":"stream","text":["Epochs: 100%|██████████| 30/30 [11:13<00:00, 22.47s/it, PPL=76.2]\n"],"name":"stderr"},{"output_type":"stream","text":["+-------+--------------------+--------------------+\n","| Epoch |     train ppl      |   validation ppl   |\n","+-------+--------------------+--------------------+\n","|   1   | 242.83639222768744 |  255.657237425029  |\n","|   2   | 196.49533537222047 |  216.80169901546   |\n","|   3   | 173.21445561826874 | 193.90740066975135 |\n","|   4   | 154.41425648884325 | 177.52847914918655 |\n","|   5   | 144.52755444060776 | 169.67785502292259 |\n","|   6   | 138.5620114201827  | 166.84398077586366 |\n","|   7   | 133.55747455313735 | 160.19204124142692 |\n","|   8   | 126.35015039799192 | 156.59096681512244 |\n","|   9   | 121.6599925734506  | 151.35376905600248 |\n","|   10  | 119.98617526111435 | 152.69672949419368 |\n","|   11  |  115.689786535443  | 148.0124090104115  |\n","|   12  | 111.43327106011913 | 143.81195109394446 |\n","|   13  | 109.9887209818037  | 142.3001638523316  |\n","|   14  | 105.78587238072492 | 139.41521957370662 |\n","|   15  | 104.39539881135778 | 138.38587915389948 |\n","|   16  | 101.72722373315679 | 136.93636534211305 |\n","|   17  | 100.1760409345683  | 136.2761735956242  |\n","|   18  | 96.90824052885317  | 133.61708658386215 |\n","|   19  | 94.17916664927456  | 131.03769713828189 |\n","|   20  | 91.44098683985816  | 129.4458535347749  |\n","|   21  | 89.25911440205135  | 128.76396331404504 |\n","|   22  | 87.16865217455343  | 127.21153946382591 |\n","|   23  | 84.41760178437684  | 125.23540506176057 |\n","|   24  | 83.30762573914184  | 125.58931561097978 |\n","|   25  | 81.00799679276926  | 123.21035814745368 |\n","|   26  |  79.5112473149686  | 123.32798902361642 |\n","|   27  | 77.97482064801443  | 122.56206174200742 |\n","|   28  | 76.76547726034956  | 121.4622284568466  |\n","|   29  |  76.2387452208966  | 121.39452816124349 |\n","|   30  | 75.93823583660787  | 120.97789836493577 |\n","+-------+--------------------+--------------------+\n","model config:\n","{'vocab_size': 10000, 'hidden_dim': 200, 'embedding_dim': 200, 'max_grad_norm': 5, 'rnn_type': 'gru', 'n_layers': 2}\n"],"name":"stdout"},{"output_type":"stream","text":["Epochs: 100%|██████████| 30/30 [10:47<00:00, 21.58s/it, PPL=52]"],"name":"stderr"},{"output_type":"stream","text":["+-------+--------------------+--------------------+\n","| Epoch |     train ppl      |   validation ppl   |\n","+-------+--------------------+--------------------+\n","|   1   | 214.76430807732635 | 236.38440097502212 |\n","|   2   | 168.22118238994702 | 197.66910132999692 |\n","|   3   | 146.4426587783555  | 181.2688765246167  |\n","|   4   | 124.98825487506203 | 156.90817319361085 |\n","|   5   | 114.36954493213622 |  150.27512423402   |\n","|   6   | 107.27670072456446 | 147.2783974959482  |\n","|   7   | 111.39265011981804 | 157.56142428215566 |\n","|   8   | 96.28858795259029  | 138.66098526505235 |\n","|   9   |  98.3523848030492  | 143.04574825551208 |\n","|   10  |  91.4629315763579  |  137.621978100531  |\n","|   11  |  88.9765327069539  | 138.66851139362402 |\n","|   12  |  85.674565236024   | 135.10610806898623 |\n","|   13  | 82.40724148120034  | 131.21234442531224 |\n","|   14  |  78.5638912554054  | 128.84017377804201 |\n","|   15  | 76.47932743599243  | 127.79410301248983 |\n","|   16  | 73.86046749647666  | 124.8537051008861  |\n","|   17  | 71.53693003417283  | 124.25401233606429 |\n","|   18  | 68.13496696350224  | 121.37156771628386 |\n","|   19  | 65.78133951967837  | 120.52093099089807 |\n","|   20  | 63.83158927326128  | 120.82864214060062 |\n","|   21  | 61.74131510403549  | 119.00257630562464 |\n","|   22  | 59.53541414848001  | 118.08694207348928 |\n","|   23  | 57.87661624207588  | 116.89204198434895 |\n","|   24  | 56.21134027323155  | 117.66721572089284 |\n","|   25  | 54.648387072817364 | 116.74468297438493 |\n","|   26  | 53.511309779644186 | 117.20297177545916 |\n","|   27  | 52.68586250689903  | 117.26731932794452 |\n","|   28  | 52.139295552659824 | 117.0771869869557  |\n","|   29  | 51.834484167707494 | 117.44721544334497 |\n","|   30  | 51.74125261350762  | 117.62310118162934 |\n","+-------+--------------------+--------------------+\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"gmydqsp_Hu_f","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"f6b400a3-353f-49ef-bd84-1ee221adc80e","executionInfo":{"status":"ok","timestamp":1589180791479,"user_tz":-180,"elapsed":2747456,"user":{"displayName":"Gal Kampel","photoUrl":"","userId":"12072246612200432478"}}},"source":["print('Networks with dropout:')\n","main(dict_h_params=params_dropout,dict_m_params=params_model,\n","     training_set=training_set, validation_set=validation_set, scalar_plot=True)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["\rEpochs:   0%|          | 0/30 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Networks with dropout:\n","hyper params config:\n","{'optimizer_dict': {'optim_name': 'SGD', 'optim_func': <class 'torch.optim.sgd.SGD'>, 'optim_params': {'momentum': 0.9, 'nesterov': False}}, 'lr': 0.5, 'weight_decay': 6e-05, 'dropout': 0.2, 'use_seq': False}\n","model config:\n","{'vocab_size': 10000, 'hidden_dim': 200, 'embedding_dim': 200, 'max_grad_norm': 5, 'rnn_type': 'lstm', 'n_layers': 2}\n"],"name":"stdout"},{"output_type":"stream","text":["Epochs: 100%|██████████| 30/30 [12:03<00:00, 24.11s/it, PPL=81.9]\n","Epochs:   0%|          | 0/30 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["+-------+--------------------+--------------------+\n","| Epoch |     train ppl      |   validation ppl   |\n","+-------+--------------------+--------------------+\n","|   1   |  260.382511606011  | 269.7536268506337  |\n","|   2   | 205.2458361989828  | 222.8421769286301  |\n","|   3   | 182.96359992032228 | 201.4032558850453  |\n","|   4   | 161.51175296843118 | 183.69245087141078 |\n","|   5   | 144.70331879447286 | 168.4434739406028  |\n","|   6   | 138.11597719631786 | 165.39420411636198 |\n","|   7   |  130.071930844337  | 157.9722322866992  |\n","|   8   | 121.83593069592322 | 152.33585189942494 |\n","|   9   | 116.55887371378026 | 146.0687608336205  |\n","|   10  | 115.65676271378771 | 148.5413534303513  |\n","|   11  | 111.6100513547887  | 145.2650170414873  |\n","|   12  | 107.09976436981458 |  140.746246170145  |\n","|   13  | 105.06680416132264 | 139.2064206548465  |\n","|   14  | 101.54182664350047 | 136.17669465684347 |\n","|   15  | 98.64249537093681  | 133.46512203725192 |\n","|   16  | 98.67333557538562  | 134.08295878269078 |\n","|   17  | 94.99590217696752  | 131.16741068328182 |\n","|   18  | 92.39280769580508  | 129.83117778734544 |\n","|   19  | 90.92747849582796  | 128.23861994896956 |\n","|   20  |  88.1951203813173  | 126.38397074862212 |\n","|   21  | 86.77476167024591  | 125.72592708786605 |\n","|   22  |  84.3127919084701  | 123.63351738602637 |\n","|   23  | 83.00419443671414  | 122.95260272977542 |\n","|   24  | 81.10021489084714  | 121.89226067816465 |\n","|   25  |  80.0335710116528  | 120.80016921226465 |\n","|   26  | 79.03813944881885  | 121.15458110147472 |\n","|   27  | 77.68626737261879  | 119.73029429696479 |\n","|   28  | 76.94220211082842  | 118.91168737201568 |\n","|   29  | 76.65444520132903  | 118.96033758731768 |\n","|   30  | 76.48821325290992  | 118.74341593351693 |\n","+-------+--------------------+--------------------+\n","model config:\n","{'vocab_size': 10000, 'hidden_dim': 200, 'embedding_dim': 200, 'max_grad_norm': 5, 'rnn_type': 'gru', 'n_layers': 2}\n"],"name":"stdout"},{"output_type":"stream","text":["Epochs: 100%|██████████| 30/30 [11:26<00:00, 22.89s/it, PPL=63.4]"],"name":"stderr"},{"output_type":"stream","text":["+-------+--------------------+--------------------+\n","| Epoch |     train ppl      |   validation ppl   |\n","+-------+--------------------+--------------------+\n","|   1   | 225.81593939621342 | 247.01578355226283 |\n","|   2   | 181.13651938899392 |  210.672496103996  |\n","|   3   | 163.9386439079125  | 199.4482157477377  |\n","|   4   | 135.95960620615108 | 168.39635807315454 |\n","|   5   | 124.34327889649965 | 161.07194747222388 |\n","|   6   | 115.18130738046696 | 155.1700273674772  |\n","|   7   | 110.69779489017861 | 154.16217569939445 |\n","|   8   | 100.20441627123438 | 144.1866130738108  |\n","|   9   | 100.94763394129326 | 147.9198826790933  |\n","|   10  | 95.31597494472466  | 143.06355387282085 |\n","|   11  | 90.77878021750382  | 140.85435605804128 |\n","|   12  |  85.6548826453511  | 135.6659577003743  |\n","|   13  | 84.50662326167934  | 134.33577703585505 |\n","|   14  | 80.54160821932379  | 132.07296470813884 |\n","|   15  | 77.48244273917352  | 127.20258571862426 |\n","|   16  | 75.07375863265366  | 125.29586237837114 |\n","|   17  | 73.74395565823366  | 125.49558407428903 |\n","|   18  | 69.77484118775777  | 120.82524451807758 |\n","|   19  | 67.79832094479026  | 120.47179263431782 |\n","|   20  | 66.54527050930314  | 120.18249040887595 |\n","|   21  | 64.49924136775633  | 117.89614073762014 |\n","|   22  | 62.63941764393883  | 116.28962684542948 |\n","|   23  | 61.44162729877463  | 114.91901985149315 |\n","|   24  | 60.24938174614334  | 114.32939557703678 |\n","|   25  | 59.13190929829591  | 113.34892180562976 |\n","|   26  | 58.499685282458074 | 113.41698721508504 |\n","|   27  | 57.80023028847339  | 112.56350402154497 |\n","|   28  | 57.40964737860428  | 112.01674704175831 |\n","|   29  | 57.19408257660516  | 112.11675987415836 |\n","|   30  | 57.15121710022751  | 112.35101711436646 |\n","+-------+--------------------+--------------------+\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"fWgUbS6SpdJ5","colab_type":"text"},"source":["## Run on test set with  best hyperparameter for each regularization"]},{"cell_type":"code","metadata":{"id":"Wsnz2Dt9iqsx","colab_type":"code","colab":{}},"source":["params_no_reg_best = OrderedDict([\n","                             ('optimizer_dict', \n","                              [{'optim_name': 'SGD', 'optim_func': optim.SGD, 'optim_params': { 'momentum':0.9, 'nesterov': True}}]),\n","                             ('lr', [0.5]), #best 0.5\n","                             ('weight_decay', [8e-5]), #best 8e-5\n","                             ('dropout', [0.0]),\n","                             ('use_seq', [False])\n","                             ])\n","\n","params_dropout_best = OrderedDict([\n","                              ('optimizer_dict',\n","                               [{'optim_name': 'SGD', 'optim_func': optim.SGD, 'optim_params': { 'momentum':0.9, 'nesterov': False}}]),\n","                              ('lr', [0.5]),\n","                             ('weight_decay', [6e-5]),\n","                             ('dropout', [0.2]), \n","                             ('use_seq', [False])\n","                             ])\n","\n","\n","params_model = OrderedDict([\n","                            ('vocab_size', [10000]), ('hidden_dim', [200]),\n","                            ('embedding_dim', [200]), ('max_grad_norm', [5]), \n","                            ('rnn_type', ['lstm', 'gru']), ('n_layers', [2])\n","                            ])\n","\n","# [{'optim_name': 'Adam', 'optim_func': optim.Adam, 'optim_params': {}}]),"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PzvqiGQiXemQ","colab_type":"code","outputId":"f2e00f6d-f3d0-4289-e784-4d52f5e63885","executionInfo":{"status":"ok","timestamp":1589183672853,"user_tz":-180,"elapsed":2725275,"user":{"displayName":"Gal Kampel","photoUrl":"","userId":"12072246612200432478"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#take best hyperparams and run on test\n","main(dict_h_params=params_no_reg_best,dict_m_params=params_model, training_set=training_set,\n","     validation_set=validation_set, tr_val_plot=True, save_model=False)\n","\n","main(dict_h_params=params_dropout_best,dict_m_params=params_model, training_set=training_set,\n","     validation_set=validation_set, tr_val_plot=True, save_model=False)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["\rEpochs:   0%|          | 0/30 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["hyper params config:\n","{'optimizer_dict': {'optim_name': 'SGD', 'optim_func': <class 'torch.optim.sgd.SGD'>, 'optim_params': {'momentum': 0.9, 'nesterov': True}}, 'lr': 0.5, 'weight_decay': 8e-05, 'dropout': 0.0, 'use_seq': False}\n","model config:\n","{'vocab_size': 10000, 'hidden_dim': 200, 'embedding_dim': 200, 'max_grad_norm': 5, 'rnn_type': 'lstm', 'n_layers': 2}\n"],"name":"stdout"},{"output_type":"stream","text":["Epochs: 100%|██████████| 30/30 [11:11<00:00, 22.37s/it, PPL=76.2]\n"],"name":"stderr"},{"output_type":"stream","text":["+-------+--------------------+--------------------+\n","| Epoch |     train ppl      |   validation ppl   |\n","+-------+--------------------+--------------------+\n","|   1   | 242.83639222768744 |  255.657237425029  |\n","|   2   | 196.49533537222047 |  216.80169901546   |\n","|   3   | 173.21445561826874 | 193.90740066975135 |\n","|   4   | 154.41425648884325 | 177.52847914918655 |\n","|   5   | 144.52755444060776 | 169.67785502292259 |\n","|   6   | 138.5620114201827  | 166.84398077586366 |\n","|   7   | 133.55747455313735 | 160.19204124142692 |\n","|   8   | 126.35015039799192 | 156.59096681512244 |\n","|   9   | 121.6599925734506  | 151.35376905600248 |\n","|   10  | 119.98617526111435 | 152.69672949419368 |\n","|   11  |  115.689786535443  | 148.0124090104115  |\n","|   12  | 111.43327106011913 | 143.81195109394446 |\n","|   13  | 109.9887209818037  | 142.3001638523316  |\n","|   14  | 105.78587238072492 | 139.41521957370662 |\n","|   15  | 104.39539881135778 | 138.38587915389948 |\n","|   16  | 101.72722373315679 | 136.93636534211305 |\n","|   17  | 100.1760409345683  | 136.2761735956242  |\n","|   18  | 96.90824052885317  | 133.61708658386215 |\n","|   19  | 94.17916664927456  | 131.03769713828189 |\n","|   20  | 91.44098683985816  | 129.4458535347749  |\n","|   21  | 89.25911440205135  | 128.76396331404504 |\n","|   22  | 87.16865217455343  | 127.21153946382591 |\n","|   23  | 84.41760178437684  | 125.23540506176057 |\n","|   24  | 83.30762573914184  | 125.58931561097978 |\n","|   25  | 81.00799679276926  | 123.21035814745368 |\n","|   26  |  79.5112473149686  | 123.32798902361642 |\n","|   27  | 77.97482064801443  | 122.56206174200742 |\n","|   28  | 76.76547726034956  | 121.4622284568466  |\n","|   29  |  76.2387452208966  | 121.39452816124349 |\n","|   30  | 75.93823583660787  | 120.97789836493577 |\n","+-------+--------------------+--------------------+\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpochs:   0%|          | 0/30 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["model config:\n","{'vocab_size': 10000, 'hidden_dim': 200, 'embedding_dim': 200, 'max_grad_norm': 5, 'rnn_type': 'gru', 'n_layers': 2}\n"],"name":"stdout"},{"output_type":"stream","text":["Epochs: 100%|██████████| 30/30 [10:45<00:00, 21.53s/it, PPL=52]\n"],"name":"stderr"},{"output_type":"stream","text":["+-------+--------------------+--------------------+\n","| Epoch |     train ppl      |   validation ppl   |\n","+-------+--------------------+--------------------+\n","|   1   | 214.76430807732635 | 236.38440097502212 |\n","|   2   | 168.22118238994702 | 197.66910132999692 |\n","|   3   | 146.4426587783555  | 181.2688765246167  |\n","|   4   | 124.98825487506203 | 156.90817319361085 |\n","|   5   | 114.36954493213622 |  150.27512423402   |\n","|   6   | 107.27670072456446 | 147.2783974959482  |\n","|   7   | 111.39265011981804 | 157.56142428215566 |\n","|   8   | 96.28858795259029  | 138.66098526505235 |\n","|   9   |  98.3523848030492  | 143.04574825551208 |\n","|   10  |  91.4629315763579  |  137.621978100531  |\n","|   11  |  88.9765327069539  | 138.66851139362402 |\n","|   12  |  85.674565236024   | 135.10610806898623 |\n","|   13  | 82.40724148120034  | 131.21234442531224 |\n","|   14  |  78.5638912554054  | 128.84017377804201 |\n","|   15  | 76.47932743599243  | 127.79410301248983 |\n","|   16  | 73.86046749647666  | 124.8537051008861  |\n","|   17  | 71.53693003417283  | 124.25401233606429 |\n","|   18  | 68.13496696350224  | 121.37156771628386 |\n","|   19  | 65.78133951967837  | 120.52093099089807 |\n","|   20  | 63.83158927326128  | 120.82864214060062 |\n","|   21  | 61.74131510403549  | 119.00257630562464 |\n","|   22  | 59.53541414848001  | 118.08694207348928 |\n","|   23  | 57.87661624207588  | 116.89204198434895 |\n","|   24  | 56.21134027323155  | 117.66721572089284 |\n","|   25  | 54.648387072817364 | 116.74468297438493 |\n","|   26  | 53.511309779644186 | 117.20297177545916 |\n","|   27  | 52.68586250689903  | 117.26731932794452 |\n","|   28  | 52.139295552659824 | 117.0771869869557  |\n","|   29  | 51.834484167707494 | 117.44721544334497 |\n","|   30  | 51.74125261350762  | 117.62310118162934 |\n","+-------+--------------------+--------------------+\n","hyper params config:\n","{'optimizer_dict': {'optim_name': 'SGD', 'optim_func': <class 'torch.optim.sgd.SGD'>, 'optim_params': {'momentum': 0.9, 'nesterov': False}}, 'lr': 0.5, 'weight_decay': 6e-05, 'dropout': 0.2, 'use_seq': False}\n","model config:\n","{'vocab_size': 10000, 'hidden_dim': 200, 'embedding_dim': 200, 'max_grad_norm': 5, 'rnn_type': 'lstm', 'n_layers': 2}\n"],"name":"stdout"},{"output_type":"stream","text":["Epochs: 100%|██████████| 30/30 [12:00<00:00, 24.01s/it, PPL=81.7]\n"],"name":"stderr"},{"output_type":"stream","text":["+-------+--------------------+--------------------+\n","| Epoch |     train ppl      |   validation ppl   |\n","+-------+--------------------+--------------------+\n","|   1   | 260.7934640400719  | 270.2426872968723  |\n","|   2   | 205.67060212728833 | 223.18379003012893 |\n","|   3   | 183.9914408173782  | 202.55476110097305 |\n","|   4   | 161.49613580341494 | 183.78705720664078 |\n","|   5   | 144.55049294567638 | 168.19058603518266 |\n","|   6   | 139.22626601342043 | 166.17952513966824 |\n","|   7   | 129.9499897392572  |   158.0979671734   |\n","|   8   | 120.60693634115523 | 151.5363615323387  |\n","|   9   | 115.27690322193814 | 144.94955488032414 |\n","|   10  | 115.59700658249977 | 148.9242409367939  |\n","|   11  | 111.10105550232704 | 145.28316606333033 |\n","|   12  | 107.6052509453132  | 141.58332052092572 |\n","|   13  | 105.03827676721092 | 139.43575883912618 |\n","|   14  | 102.01255448449119 | 136.80491278582053 |\n","|   15  | 98.48208454531223  | 133.92053978921706 |\n","|   16  | 98.01422437583226  | 133.49321745165798 |\n","|   17  | 94.45101442927277  | 131.18513469582714 |\n","|   18  | 91.77454056075553  | 129.01854109429001 |\n","|   19  | 91.13660987440475  | 128.54979604873427 |\n","|   20  | 87.98510801122652  | 125.85553126218232 |\n","|   21  | 86.14456373882075  | 125.38389052709545 |\n","|   22  | 83.92308642846528  | 123.39426533385885 |\n","|   23  | 82.46028002319812  | 122.15444951059258 |\n","|   24  | 80.98265913203211  | 121.73557089540272 |\n","|   25  | 79.59350608003568  | 120.12896085436512 |\n","|   26  | 78.55679879210469  | 120.20338561262427 |\n","|   27  | 77.50983874009385  | 119.47728597453089 |\n","|   28  | 76.72122614947246  | 118.65254742716952 |\n","|   29  |  76.4426547874615  | 118.44488230117881 |\n","|   30  |  76.2898259847098  | 118.48946258129922 |\n","+-------+--------------------+--------------------+\n","model config:\n","{'vocab_size': 10000, 'hidden_dim': 200, 'embedding_dim': 200, 'max_grad_norm': 5, 'rnn_type': 'gru', 'n_layers': 2}\n"],"name":"stdout"},{"output_type":"stream","text":["Epochs: 100%|██████████| 30/30 [11:25<00:00, 22.84s/it, PPL=63.6]"],"name":"stderr"},{"output_type":"stream","text":["+-------+--------------------+--------------------+\n","| Epoch |     train ppl      |   validation ppl   |\n","+-------+--------------------+--------------------+\n","|   1   | 221.32402615658307 | 242.11712771366413 |\n","|   2   | 176.56560650646955 | 206.27054279416555 |\n","|   3   | 158.4696762912484  | 193.33306781380503 |\n","|   4   | 134.17017168421475 | 166.63616394139416 |\n","|   5   | 122.48399250305819 | 159.5985186739808  |\n","|   6   | 113.80788932391006 | 154.58421074387547 |\n","|   7   | 108.01605220740352 | 150.48418399175293 |\n","|   8   | 98.43622708351354  | 141.4513151150974  |\n","|   9   | 100.16601014929758 | 146.46354841939274 |\n","|   10  | 95.17395418717469  | 143.0365228238252  |\n","|   11  |  90.8341760471471  | 140.55523795908692 |\n","|   12  | 87.25519621910908  | 138.14530932393708 |\n","|   13  |  84.0078100323804  | 133.99426497180858 |\n","|   14  | 80.50278935557961  | 131.99364159088148 |\n","|   15  | 77.46253526045692  | 127.5571432346587  |\n","|   16  | 75.20934045133171  | 125.44148352510395 |\n","|   17  | 73.85401354991667  | 126.35889650321995 |\n","|   18  |  70.1104489821546  | 121.91716460919494 |\n","|   19  | 67.85750742051925  | 120.5104090558267  |\n","|   20  | 66.63245102807457  | 120.20071206814315 |\n","|   21  | 64.75596880715285  | 118.07003856059828 |\n","|   22  | 62.80456589200762  | 116.57689890372959 |\n","|   23  | 61.49353486709903  | 115.04611722604895 |\n","|   24  | 60.345990202135745 | 114.75761584492659 |\n","|   25  | 59.20288842899724  | 113.71656892895508 |\n","|   26  | 58.57070348491501  |  113.72686693888   |\n","|   27  | 57.928389227195005 | 113.02643702668004 |\n","|   28  | 57.53772316526358  | 112.56021036304293 |\n","|   29  | 57.31740831384975  | 112.54151377629307 |\n","|   30  |  57.2626799586852  | 112.85161700975391 |\n","+-------+--------------------+--------------------+\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"9p4sFgxlprIy","colab_type":"text"},"source":["## Test pre-trained model\n"]},{"cell_type":"code","metadata":{"id":"mdHWc5KnfuRY","colab_type":"code","colab":{}},"source":["DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","EPOCHS = 30\n","FOLDER_MODEL = os.path.join(os.getcwd(), FOLDER_CHECKPOINT)\n","\n","def evaluate_final_model(model, eval_loader, batch_size, criterion, device):\n","        device = device\n","        ppl = 0\n","        with torch.no_grad():\n","            model.eval()\n","            h = model.init_hidden(batch_size, device)\n","            running_loss = 0.0\n","            eval_loader_size = 0\n","            for eval_seq, eval_labels in eval_loader:\n","                eval_seq, eval_labels = eval_seq.to(device), eval_labels.to(device)\n","                logits, h = model(eval_seq, h) \n","                h = detach_hidden(model, h)\n","                loss = criterion(logits, eval_labels.view(-1))\n","                running_loss += loss.item()\n","                eval_loader_size += 1\n","            ppl = np.exp(running_loss / eval_loader_size)\n","        return ppl\n","\n","def detach_hidden(model, h):\n","    if model.get_rnn_type() == 'lstm':\n","        return tuple([el.data for el in h])  # tuple([el.detach() for el in h])\n","    elif model.get_rnn_type() == 'gru':\n","        return h.data # h.detach()\n","\n","# evaluate on train and test\n","def get_best_model_ppl(dict_best_h_params, model_params_best, dict_dataset,\n","                       model_best_path): \n","    config_h_params = HyperparamsConfig(dict_best_h_params)\n","    config_best = next(config_h_params.create_configs())\n","    # print(f'config = {config_best}\\nmodel_params_best = {model_params_best}')\n","    # print(f'model_best_path = {model_best_path}')\n","    model_run = ModelRun(config_best, model_params_best, EPOCHS, DEVICE, \n","                         model_best_path)\n","    best_model = model_run.get_model()\n","    criterion = nn.CrossEntropyLoss()\n","    dataset_types = list(dict_dataset.keys())\n","    # model_name, best_epoch = model_run.get_model_name().split('_epoch=')\n","    model_name = model_run.get_model_name()\n","    # print(f'config_best = {config_best} (epoch = {best_epoch}):')\n","    header = ['Model'] + [f'{dataset_type} ppl' for dataset_type in dict_dataset.keys()]\n","    t = PrettyTable(header)\n","    vals = [model_name]\n","    for dataset in dict_dataset.values():\n","        ppl_val = evaluate_final_model(best_model, create_data_loader(dataset),\n","                                       BATCH_SIZE, criterion, DEVICE)\n","        vals.append(ppl_val)\n","    t.add_row(vals)\n","    print(t)\n","    return vals"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"78jRS5gLCQ7q","colab_type":"text"},"source":["* Load best hyperparameters for each regularizer\n","* print best results for training/validation/test"]},{"cell_type":"code","metadata":{"id":"anUDxDliCMic","colab_type":"code","colab":{}},"source":["params_no_reg_best = OrderedDict([\n","                             ('optimizer_dict', \n","                              [{'optim_name': 'SGD', 'optim_func': optim.SGD, 'optim_params': { 'momentum':0.9, 'nesterov': True}}]),\n","                             ('lr', [0.5]), #best 0.5\n","                             ('weight_decay', [8e-5]), #best 8e-5\n","                             ('dropout', [0.0]),\n","                             ('use_seq', [False])\n","                             ])\n","\n","params_dropout_best =  OrderedDict([\n","                              ('optimizer_dict',\n","                               [{'optim_name': 'SGD', 'optim_func': optim.SGD, 'optim_params': { 'momentum':0.9, 'nesterov': False}}]),\n","                              ('lr', [0.5]),\n","                             ('weight_decay', [6e-5]),\n","                             ('dropout', [0.2]), \n","                             ('use_seq', [False])\n","                             ])\n","\n","dict_dataset = OrderedDict([\n","                              ('train', training_set),\n","                              ('validation',validation_set),\n","                              ('test', test_set)\n","                              ])\n","\n","params_model_lstm_best = OrderedDict([\n","                                  ('vocab_size', 10000), ('hidden_dim', 200),\n","                                  ('embedding_dim', 200), ('max_grad_norm', 5), \n","                                  ('rnn_type', 'lstm'), ('n_layers', 2)\n","                                  ])\n","params_model_gru_best = OrderedDict([\n","                                  ('vocab_size', 10000), ('hidden_dim', 200),\n","                                  ('embedding_dim', 200), ('max_grad_norm', 5), \n","                                  ('rnn_type', 'gru'), ('n_layers', 2)\n","                                  ])\n","model_lstm_no_reg_filename = 'WordPredictor_lstm_optimizer=SGD_lr=0.5_dropout=0.0_weight_decay=8e-05_epoch=30'\n","model_lstm_dropout_filename = 'WordPredictor_lstm_optimizer=SGD_lr=0.5_dropout=0.2_weight_decay=6e-05_epoch=30'\n","model_gru_no_reg_filename = 'WordPredictor_gru_optimizer=SGD_lr=0.5_dropout=0.0_weight_decay=8e-05_epoch=30'\n","model_gru_dropout_filename = 'WordPredictor_gru_optimizer=SGD_lr=0.5_dropout=0.2_weight_decay=6e-05_epoch=30'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"A4UB5FQB_A4y","colab_type":"code","outputId":"c9d81f6e-acd1-4e50-e1eb-366bac44ecc9","executionInfo":{"status":"ok","timestamp":1589185313743,"user_tz":-180,"elapsed":24099,"user":{"displayName":"Gal Kampel","photoUrl":"","userId":"12072246612200432478"}},"colab":{"base_uri":"https://localhost:8080/","height":475}},"source":["\n","print('pre-trained no regularization (best) perplexity:')\n","\n","model_lstm_no_reg_best_path = os.path.join(FOLDER_MODEL, f'{model_lstm_no_reg_filename}.pth')\n","model_gru_no_reg_best_path = os.path.join(FOLDER_MODEL, f'{model_gru_no_reg_filename}.pth')\n","\n","get_best_model_ppl(params_no_reg_best, params_model_lstm_best, dict_dataset,\n","                   model_lstm_no_reg_best_path)\n","get_best_model_ppl(params_no_reg_best, params_model_gru_best, dict_dataset,\n","                   model_gru_no_reg_best_path)\n","print('pre-trained dropout (best) perplexity:')\n","model_lstm_dropout_best_path = os.path.join(FOLDER_MODEL, f'{model_lstm_dropout_filename}.pth')\n","model_gru_dropout_best_path = os.path.join(FOLDER_MODEL, f'{model_gru_dropout_filename}.pth')\n","get_best_model_ppl(params_dropout_best, params_model_lstm_best, dict_dataset,\n","                   model_lstm_dropout_best_path)\n","get_best_model_ppl(params_dropout_best, params_model_gru_best, dict_dataset,\n","                   model_gru_dropout_best_path)"],"execution_count":46,"outputs":[{"output_type":"stream","text":["pre-trained no regularization (best) perplexity:\n","+------------------------------------------------------------------------+------------------+--------------------+--------------------+\n","|                                 Model                                  |    train ppl     |   validation ppl   |      test ppl      |\n","+------------------------------------------------------------------------+------------------+--------------------+--------------------+\n","| WordPredictor_lstm_optimizer=SGD_lr=0.5_dropout=0.0_weight_decay=8e-05 | 75.9019803664578 | 121.05276656648577 | 117.27697678328056 |\n","+------------------------------------------------------------------------+------------------+--------------------+--------------------+\n","+-----------------------------------------------------------------------+-------------------+--------------------+-------------------+\n","|                                 Model                                 |     train ppl     |   validation ppl   |      test ppl     |\n","+-----------------------------------------------------------------------+-------------------+--------------------+-------------------+\n","| WordPredictor_gru_optimizer=SGD_lr=0.5_dropout=0.0_weight_decay=8e-05 | 51.76338663448282 | 117.43597301914332 | 114.2400568778077 |\n","+-----------------------------------------------------------------------+-------------------+--------------------+-------------------+\n","pre-trained dropout (best) perplexity:\n","+------------------------------------------------------------------------+-------------------+--------------------+--------------------+\n","|                                 Model                                  |     train ppl     |   validation ppl   |      test ppl      |\n","+------------------------------------------------------------------------+-------------------+--------------------+--------------------+\n","| WordPredictor_lstm_optimizer=SGD_lr=0.5_dropout=0.2_weight_decay=6e-05 | 76.48290116532499 | 118.67345741091269 | 115.15198143923045 |\n","+------------------------------------------------------------------------+-------------------+--------------------+--------------------+\n","+-----------------------------------------------------------------------+-------------------+--------------------+--------------------+\n","|                                 Model                                 |     train ppl     |   validation ppl   |      test ppl      |\n","+-----------------------------------------------------------------------+-------------------+--------------------+--------------------+\n","| WordPredictor_gru_optimizer=SGD_lr=0.5_dropout=0.2_weight_decay=6e-05 | 57.13682047669609 | 112.33672053903588 | 109.04050665553807 |\n","+-----------------------------------------------------------------------+-------------------+--------------------+--------------------+\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["['WordPredictor_gru_optimizer=SGD_lr=0.5_dropout=0.2_weight_decay=6e-05',\n"," 57.13682047669609,\n"," 112.33672053903588,\n"," 109.04050665553807]"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"code","metadata":{"id":"x0rO--J6B5Jj","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}